{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificially-Created Data Prediction Using Daimensions\n",
    "\n",
    "This dataset was artificially created with a specific rule in mind. The goal of this notebook is to show how Daimensions handles data created by a specified rule. Bertrand, the cofounder of Brainome, made this dataset, so the csv's are named after him."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,1,0,0,0,0,0,0,0,1,1\r",
      "\r\n",
      "1,1,1,0,0,1,0,1,0,1,0\r",
      "\r\n",
      "0,1,0,1,0,1,0,0,0,1,0\r",
      "\r\n",
      "0,0,1,1,0,1,0,1,0,1,1\r",
      "\r\n",
      "0,0,1,0,0,0,1,0,1,1,1\r",
      "\r\n",
      "0,0,1,1,1,1,0,0,1,1,0\r",
      "\r\n",
      "0,0,1,1,1,1,0,0,0,0,0\r",
      "\r\n",
      "0,0,1,0,0,1,1,0,1,1,1\r",
      "\r\n",
      "1,1,1,0,1,1,1,1,0,0,1\r",
      "\r\n",
      "0,0,0,0,1,0,1,0,0,1,1\r",
      "\r\n"
     ]
    }
   ],
   "source": [
    "! head bertrandtrain.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see from above, this data doesn't have column names. Because of this, we have to use -headerless when measuring our data and building our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Get Measurements\n",
    "\n",
    "We always want to measure our data before building our predictor in order to ensure we are building the right model. For more information about how to use Daimensions and why we want to measure our data beforehand, check out the Titanic notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brainome Daimensions(tm) 0.97 Copyright (c) 2019, 2020 by Brainome, Inc. All Rights Reserved.\n",
      "Licensed to: Ariana Park\n",
      "Expiration date: 2020-11-30 (102 days left)\n",
      "Number of threads: 1\n",
      "Maximum file size: 4GB\n",
      "Connected to: https://beta.brainome.ai:8080\n",
      "\n",
      "Data:\n",
      "Number of instances: 13187\n",
      "Number of attributes: 10\n",
      "Number of classes: 2\n",
      "Class balance: 37.35% 62.65%\n",
      "\n",
      "Learnability:\n",
      "Best guess accuracy: 62.65%\n",
      "Capacity progression (# of decision points): [13, 14, 15, 15, 16, 16]\n",
      "Decision Tree: 5993 parameters\n",
      "Estimated Memory Equivalent Capacity for Neural Networks: 157 parameters\n",
      "\n",
      "Risk that model needs to overfit for 100% accuracy...\n",
      "using Decision Tree: 90.91%\n",
      "using Neural Networks: 100.00%\n",
      "\n",
      "Expected Generalization...\n",
      "using Decision Tree: 2.20 bits/bit\n",
      "using a Neural Network: 83.99 bits/bit\n",
      "\n",
      "Recommendations:\n",
      "Note: Maybe enough data to generalize. [yellow]\n",
      "Warning: Cannot find numpy. The output predictor may not run on this machine.\n",
      "\n",
      "Time estimate for a Neural Network:\n",
      "Estimated time to architect: 0d 0h 0m 15s\n",
      "Estimated time to prime (subject to change after model architecting): 0d 0h 3m 26s\n",
      "\n",
      "Time estimate for Decision Tree:\n",
      "Estimated time to prime a decision tree: less than a minute\n"
     ]
    }
   ],
   "source": [
    "! btc -measureonly bertrandtrain.csv -headerless"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build the Predictor\n",
    "\n",
    "Based on our measurements, Daimensions recommends we use a neural network, which has 83.99 bits/bit of expected generalization for this dataset. Don't forget to use -headerless."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brainome Daimensions(tm) 0.97 Copyright (c) 2019, 2020 by Brainome, Inc. All Rights Reserved.\n",
      "Licensed to: Ariana Park\n",
      "Expiration date: 2020-11-30 (102 days left)\n",
      "Number of threads: 1\n",
      "Maximum file size: 4GB\n",
      "Connected to: https://beta.brainome.ai:8080\n",
      "\n",
      "Running btc will overwrite existing bertrand_predict.py. OK? [y/N] yes\n",
      "Data:\n",
      "Number of instances: 13187\n",
      "Number of attributes: 10\n",
      "Number of classes: 2\n",
      "Class balance: 37.35% 62.65%\n",
      "\n",
      "Learnability:\n",
      "Best guess accuracy: 62.65%\n",
      "Capacity progression (# of decision points): [13, 14, 15, 15, 16, 16]\n",
      "Decision Tree: 5993 parameters\n",
      "Estimated Memory Equivalent Capacity for Neural Networks: 157 parameters\n",
      "\n",
      "Risk that model needs to overfit for 100% accuracy...\n",
      "using Decision Tree: 90.91%\n",
      "using Neural Networks: 100.00%\n",
      "\n",
      "Expected Generalization...\n",
      "using Decision Tree: 2.20 bits/bit\n",
      "using a Neural Network: 83.99 bits/bit\n",
      "\n",
      "Recommendations:\n",
      "Note: Maybe enough data to generalize. [yellow]\n",
      "Warning: Cannot find numpy. The output predictor may not run on this machine.\n",
      "\n",
      "Time estimate for a Neural Network:\n",
      "Estimated time to architect: 0d 0h 0m 14s\n",
      "Estimated time to prime (subject to change after model architecting): 0d 0h 3m 23s\n",
      "Note: Machine learner type NN given by user.\n",
      "Model capacity (MEC):     49 bits\n",
      "Architecture efficiency:   1.0 bits/parameter\n",
      "\n",
      "Estimated time to prime model: 0d 0h 2m 30s\n",
      "\n",
      "Priming model...done.\n",
      "Estimated training time: 0d 0h 19m 34s\n",
      "\n",
      "Training...done.\n",
      "Classifier Type:                    Neural Network\n",
      "System Type:                        Binary classifier\n",
      "Best-guess accuracy:                62.65%\n",
      "Model accuracy:                     100.00% (13187/13187 correct)\n",
      "Improvement over best guess:        37.35% (of possible 37.35%)\n",
      "Model capacity (MEC):               49 bits\n",
      "Generalization ratio:               269.12 bits/bit\n",
      "Model efficiency:                   0.76%/parameter\n",
      "System behavior\n",
      "True Negatives:                     37.35% (4925/13187)\n",
      "True Positives:                     62.65% (8262/13187)\n",
      "False Negatives:                    0.00% (0/13187)\n",
      "False Positives:                    0.00% (0/13187)\n",
      "True Pos. Rate/Sensitivity/Recall:  1.00\n",
      "True Neg. Rate/Specificity:         1.00\n",
      "Precision:                          1.00\n",
      "F-1 Measure:                        1.00\n",
      "False Negative Rate/Miss Rate:      0.00\n",
      "Critical Success Index:             1.00\n",
      "Overfitting:                        No\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! btc -f NN bertrandtrain.csv -o bertrand_predict.py -headerless -e 10 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Make a Prediction\n",
    "\n",
    "Hooray! Our model has 100% accuracy. Now we can use our model to make predictions on test data, a separate set of data that wasn't used for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0,0,1,1,0,1,1,0,0,0,Prediction\r\n",
      "0,0,0,0,0,0,0,0,0,0,0\r\n",
      "0,0,0,0,0,0,0,0,0,0,0\r\n",
      "1,1,0,0,1,0,0,1,1,1,0\r\n",
      "1,1,1,1,1,1,1,1,1,1,1\r\n",
      "1,1,1,1,1,1,1,1,1,1,1\r\n",
      "1,1,1,1,1,1,1,1,1,1,1\r\n",
      "0,0,1,1,0,1,1,0,0,0,1\r\n",
      "0,0,0,0,0,0,0,0,0,0,0\r\n",
      "1,1,0,0,1,0,0,1,1,1,0\r\n"
     ]
    }
   ],
   "source": [
    "! python3 bertrand_predict.py bertrandtest.csv > bertrand_prediction.csv\n",
    "! head bertrand_prediction.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
