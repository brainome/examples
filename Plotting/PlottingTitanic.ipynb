{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting Titanic Prediction\n",
    "\n",
    "This notebook is a tutorial of how we can modify the predictor python script to show a visualization of the data in the hidden space and how the predictor classifies each point. Each dimension of the hidden space corresponds to a neuron from the predictor. Because only two neurons are used for the titanic prediction model, we can plot it in the hidden space. \n",
    "*Note: This isn't part of Daimensions. We are going to manually edit the python script to output a png of the model's results in the hidden space.*\n",
    "\n",
    "## 1. Build the Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING: Could not detect a GPU. Neural Network generation will be slow.\n",
      "\n",
      "Brainome Daimensions(tm) 0.99 Copyright (c) 2019 - 2021 by Brainome, Inc. All Rights Reserved.\n",
      "Licensed to:              Alexander Makhratchev  (Evaluation)\n",
      "Expiration Date:          2021-04-30   56 days left\n",
      "Number of Threads:        1\n",
      "Maximum File Size:        30 GB\n",
      "Maximum Instances:        unlimited\n",
      "Maximum Attributes:       unlimited\n",
      "Maximum Classes:          unlimited\n",
      "Connected to:             daimensions.brainome.ai  (local execution)\n",
      "\n",
      "\n",
      "\n",
      "Command:\n",
      "    btc -f NN titanic_train.csv -o vis_titanic.py -target Survived -rank -e 5 --yes\n",
      "\n",
      "Start Time:                 03/05/2021, 18:23\n",
      "\n",
      "Attribute Ranking:\n",
      "    Important columns:          Sex, SibSp, Parch, Pclass\n",
      "    Overfit risk:                   0.0%\n",
      "    Ignoring columns:           PassengerId, Name, Age, Ticket, Fare, Cabin, Embarked\n",
      "    Test Accuracy Progression:     Sex :   78.68%\n",
      "                                   SibSp :   79.69%  change   +1.01%\n",
      "                                   Parch :   80.36%  change   +0.67%\n",
      "                                   Pclass :   80.92%  change   +0.56%\n",
      "                                   \n",
      "\n",
      "\n",
      "\n",
      "Data:\n",
      "    Input:                      titanic_train.csv\n",
      "    Target Column:              Survived\n",
      "    Number of instances:        891\n",
      "    Number of attributes:       4\n",
      "    Number of classes:          2\n",
      "    Class Balance:              0: 61.62%, 1: 38.38%\n",
      "\n",
      "Learnability:\n",
      "    Best guess accuracy:          61.62%\n",
      "    Data Sufficiency:            Maybe enough data to generalize. [yellow]\n",
      "\n",
      "Capacity Progression:            at [ 5%, 10%, 20%, 40%, 80%, 100% ]\n",
      "    Optimal Machine Learner:           5,   6,   7,   7,   8,   8\n",
      "\n",
      "\n",
      "Estimated Memory Equivalent Capacity for...\n",
      "    Decision Tree:                     1 parameters\n",
      "    Neural Networks:                  16 parameters\n",
      "    Random Forest:                    32 parameters\n",
      "\n",
      "Risk that model needs to overfit for 100% accuracy using...\n",
      "    Decision Tree:                 0.29%\n",
      "    Neural Networks:             100.00%\n",
      "    Random Forest:                16.49%\n",
      "\n",
      "Expected Generalization using...\n",
      "    Decision Tree:                692.67 bits/bit\n",
      "    Neural Network:                17.62 bits/bit\n",
      "    Random Forest:                 27.84 bits/bit\n",
      "\n",
      "\n",
      "Recommendations:\n",
      "\n",
      "\n",
      "    Note: Machine learner type NN given by user.\n",
      "\n",
      "\n",
      "Time to Build Estimates:\n",
      "\n",
      "    Neural Network:              2 minutes\n",
      "\n",
      "\n",
      "\n",
      "System Meter:                          vis_titanic.py\n",
      "    Classifier Type:                   Neural Network\n",
      "    System Type:                       Binary classifier\n",
      "    Training/Validation Split:           50% : 50%\n",
      "    Accuracy:\n",
      "        Best-guess accuracy:               61.61%\n",
      "        Training accuracy:                 78.42% (349/445 correct)\n",
      "        Validation Accuracy:               82.28% (367/446 correct)\n",
      "        Overall Model Accuracy:            80.35% (716/891 correct)\n",
      "        Improvement over best guess:       18.74% of possible  38.39%\n",
      "\n",
      "    Model Capacity (MEC):                       1 bit\n",
      "    Generalization Ratio:                  335.39 bits/bit\n",
      "    Model Efficiency:                       18.73 /parameter\n",
      "    Generalization Index:                  165.13\n",
      "    Percent of Data Memorized:               0.61%\n",
      "\n",
      "    Training Confusion Matrix (count):\n",
      "                   0 |  254   20 \n",
      "                   1 |   76   95 \n",
      "\n",
      "    Validation Confusion Matrix (count):\n",
      "                   0 |  259   16 \n",
      "                   1 |   63  108 \n",
      "\n",
      "    Full Confusion Matrix (count):\n",
      "                   0 |  513   36 \n",
      "                   1 |  139  203 \n",
      "\n",
      "    Accuracy by Class:\n",
      "               class |   TP   FP   TN   FN     TPR      TNR      PPV      NPV       F1       TS \n",
      "                   0 |  513   36  203  139   78.68%   59.36%   93.44%   59.36%   85.43%   74.56%\n",
      "                   1 |  203  139  513   36   84.94%   93.44%   59.36%   93.44%   69.88%   53.70%\n",
      "\n",
      "End Time:                     \n",
      "Runtime Duration:             \n",
      "\n",
      "\n",
      "\u001b[1A\u001b[1B\u001b[0G\u001b[?25l[+] Building 0.0s (0/1)                                                         \n",
      "\u001b[?25h\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.1s (1/2)                                                         \n",
      "\u001b[34m => [internal] load build definition from btc-dockerfile.12551             0.1s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 239B                                       0.0s\n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.2s (3/3)                                                         \n",
      "\u001b[34m => [internal] load build definition from btc-dockerfile.12551             0.1s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 239B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/brainome/btc_local_cpu:alpha    0.0s\n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.4s (7/8)                                                         \n",
      "\u001b[34m => [internal] load build definition from btc-dockerfile.12551             0.1s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 239B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/brainome/btc_local_cpu:alpha    0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.1s\n",
      "\u001b[0m\u001b[34m => => transferring context: 1.37kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => [1/3] FROM docker.io/brainome/btc_local_cpu:alpha                      0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/3] RUN adduser --disabled-password --gecos '' --uid 501 --g  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [3/3] COPY --chown=501:20 .daimensions.key /btc-alex            0.0s\n",
      "\u001b[0m => exporting to image                                                     0.1s\n",
      "\u001b[34m => => exporting layers                                                    0.0s\n",
      "\u001b[0m => => writing image sha256:43dd56f18fcffcdd02c290bfcce87c7a6cd0b9ccf4db3  0.0s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.4s (8/8) FINISHED                                                \n",
      "\u001b[34m => [internal] load build definition from btc-dockerfile.12551             0.1s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 239B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/brainome/btc_local_cpu:alpha    0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.1s\n",
      "\u001b[0m\u001b[34m => => transferring context: 1.37kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => [1/3] FROM docker.io/brainome/btc_local_cpu:alpha                      0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/3] RUN adduser --disabled-password --gecos '' --uid 501 --g  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [3/3] COPY --chown=501:20 .daimensions.key /btc-alex            0.0s\n",
      "\u001b[0m\u001b[34m => exporting to image                                                     0.1s\n",
      "\u001b[0m\u001b[34m => => exporting layers                                                    0.0s\n",
      "\u001b[0m\u001b[34m => => writing image sha256:43dd56f18fcffcdd02c290bfcce87c7a6cd0b9ccf4db3  0.0s\n",
      "\u001b[0m\u001b[34m => => naming to docker.io/library/btc-alex:latest                         0.0s\n",
      "\u001b[0m\u001b[?25hDocker image btc-alex:latest updated successfully.\n"
     ]
    }
   ],
   "source": [
    "! btc -f NN titanic_train.csv -o vis_titanic.py -target Survived -rank -e 5 --yes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Make Changes to Python Script\n",
    "\n",
    "The previous line of code should output a python script 'vis_titanic.py' with the model's predictor. Next, we'll manually edit the code by adding a few lines so that it will output the desired png when we run -validate. I'll show you the section of code we'll change with the modified lines highlighted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "codehighlighter": [
     [
      16,
      18
     ],
     [
      61,
      65
     ],
     [
      5,
      6
     ],
     [
      68,
      69
     ],
     [
      73,
      77
     ]
    ]
   },
   "outputs": [],
   "source": [
    "# Helper (save an import)\n",
    "def argmax(l):\n",
    "    f = lambda i: l[i]\n",
    "    return max(range(len(l)), key=f)\n",
    "# Classifier\n",
    "def single_classify(row, ax):\n",
    "    #inits\n",
    "    x = row\n",
    "    o = [0] * num_output_logits\n",
    "\n",
    "\n",
    "    #Nueron Equations\n",
    "    h_0 = max((((-0.23418278 * float(x[0]))+ (0.2055268 * float(x[1]))+ (-3.683856 * float(x[2]))) + -0.5669335), 0)\n",
    "    h_1 = max((((3.1762295 * float(x[0]))+ (0.29285425 * float(x[1]))+ (-0.0113988025 * float(x[2]))) + 1.4681039), 0)\n",
    "    o[0] = (0.6990876 * h_0)+ (-0.89847755 * h_1) + 2.2160573\n",
    "\n",
    "    #visualization modification\n",
    "    ax.scatter(h_0, h_1, marker=('o' if o[0] >= 0 else '^'), c=('r' if o[0] >= 0 else 'b'))\n",
    "\n",
    "\n",
    "    #Output Decision Rule\n",
    "    if num_output_logits==1:\n",
    "        return o[0]>=0\n",
    "    else:\n",
    "        return argmax(o)\n",
    "\n",
    "\n",
    "def classify(arr):\n",
    "    #init\n",
    "    w_h = np.array([[-0.23418277502059937, 0.20552679896354675, -3.6838560104370117], [3.176229476928711, 0.2928542494773865, -0.011398802511394024]])\n",
    "    b_h = np.array([-0.5669335126876831, 1.4681038856506348])\n",
    "    w_o = np.array([[0.6990876197814941, -0.8984775543212891]])\n",
    "    b_o = np.array(2.216057300567627)\n",
    "\n",
    "    #Hidden Layer\n",
    "    h = np.dot(arr, w_h.T) + b_h\n",
    "\n",
    "    relu = np.maximum(h, np.zeros_like(h))\n",
    "\n",
    "\n",
    "    #Output\n",
    "    out = np.dot(relu, w_o.T) + b_o\n",
    "    if num_output_logits == 1:\n",
    "        return (out >= 0).astype('int').reshape(-1)\n",
    "    else:\n",
    "        return (np.argmax(out, axis=1)).reshape(-1)\n",
    "\n",
    "\n",
    "\n",
    "def Predict(arr,headerless,csvfile, get_key, classmapping):\n",
    "    \n",
    "    with open(csvfile, 'r') as csvinput:\n",
    "        #readers and writers\n",
    "        writer = csv.writer(sys.stdout, lineterminator=os.linesep)\n",
    "        reader = csv.reader(csvinput)\n",
    "\n",
    "        #print original header\n",
    "        if (not headerless):\n",
    "            writer.writerow(','.join(next(reader, None) + [\"Prediction\"]))\n",
    "\n",
    "\n",
    "        #visualization modification\n",
    "        import matplotlib.pyplot as plt\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111)\n",
    "\n",
    "        for i, row in enumerate(reader):\n",
    "            #use the transformed array as input to predictor\n",
    "            pred = str(get_key(int(single_classify(arr[i],ax)), classmapping))\n",
    "            #use original untransformed line to write out\n",
    "            row.append(pred)\n",
    "            writer.writerow(row)\n",
    "\n",
    "        #visualization modification\n",
    "        ax.set_xlabel('h0')\n",
    "        ax.set_ylabel('h1')\n",
    "        plt.savefig('titanic_visual.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run -validate\n",
    "\n",
    "You can make this modification in your own python script most easily by replacing lines 359-422 with the code above. Below I'm using an already modified version of the script called 'vis_titanic_mod.py', but you would use your edited 'vis_titanic.py'. We simply have to run the following line of code and it will output our desired png."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "S,e,x,\",\",P,a,r,c,h,\",\",F,a,r,e,\",\",P,r,e,d,i,c,t,i,o,n\n",
      "male,0,7.8292,0\n",
      "female,0,7,1\n",
      "male,0,9.6875,0\n",
      "male,0,8.6625,0\n",
      "female,1,12.2875,1\n",
      "male,0,9.225,0\n",
      "female,0,7.6292,1\n",
      "male,1,29,0\n",
      "female,0,7.2292,1\n",
      "male,0,24.15,0\n",
      "male,0,7.8958,0\n",
      "male,0,26,0\n",
      "female,0,82.2667,1\n",
      "male,0,26,0\n",
      "female,0,61.175,1\n",
      "female,0,27.7208,1\n",
      "male,0,12.35,0\n",
      "male,0,7.225,0\n",
      "female,0,7.925,1\n",
      "female,0,7.225,1\n",
      "male,0,59.4,0\n",
      "male,1,3.1708,0\n",
      "female,0,31.6833,1\n",
      "male,1,61.3792,0\n",
      "female,3,262.375,1\n",
      "male,0,14.5,0\n",
      "female,1,61.9792,1\n",
      "male,0,7.225,0\n",
      "male,0,30.5,0\n",
      "male,0,21.6792,0\n",
      "male,0,26,0\n",
      "male,0,31.5,0\n",
      "female,2,20.575,1\n",
      "female,2,23.45,1\n",
      "male,0,57.75,0\n",
      "male,0,7.2292,0\n",
      "female,0,8.05,1\n",
      "female,0,8.6625,1\n",
      "male,0,9.5,0\n",
      "male,0,56.4958,0\n",
      "male,1,13.4167,0\n",
      "male,0,26.55,0\n",
      "male,0,7.85,0\n",
      "female,0,13,1\n",
      "female,0,52.5542,1\n",
      "male,0,7.925,0\n",
      "male,0,29.7,0\n",
      "male,0,7.75,0\n",
      "female,0,76.2917,1\n",
      "female,2,15.9,1\n",
      "male,0,60,0\n",
      "male,0,15.0333,0\n",
      "female,1,23,1\n",
      "female,2,263,1\n",
      "male,0,15.5792,0\n",
      "male,1,29.125,0\n",
      "male,0,7.8958,0\n",
      "male,0,7.65,0\n",
      "male,0,16.1,0\n",
      "female,0,262.375,1\n",
      "male,0,7.8958,0\n",
      "male,0,13.5,0\n",
      "male,0,7.75,0\n",
      "female,0,7.725,1\n",
      "male,2,262.375,1\n",
      "female,0,21,1\n",
      "female,0,7.8792,1\n",
      "male,0,42.4,0\n",
      "male,0,28.5375,0\n",
      "female,4,263,1\n",
      "female,0,7.75,1\n",
      "male,0,7.8958,0\n",
      "female,0,7.925,1\n",
      "male,0,27.7208,0\n",
      "female,0,211.5,1\n",
      "male,0,211.5,1\n",
      "male,0,8.05,0\n",
      "female,0,25.7,1\n",
      "male,0,13,0\n",
      "female,0,7.75,1\n",
      "male,1,15.2458,0\n",
      "male,0,221.7792,1\n",
      "male,0,26,0\n",
      "male,0,7.8958,0\n",
      "male,0,10.7083,0\n",
      "male,0,14.4542,0\n",
      "female,0,7.8792,1\n",
      "female,0,8.05,1\n",
      "female,0,7.75,1\n",
      "male,1,23,0\n",
      "female,0,13.9,1\n",
      "male,0,7.775,0\n",
      "female,2,52,1\n",
      "male,0,8.05,0\n",
      "male,0,26,0\n",
      "male,0,7.7958,0\n",
      "female,0,78.85,1\n",
      "male,0,7.925,0\n",
      "female,0,7.8542,1\n",
      "male,0,8.05,0\n",
      "female,0,55.4417,1\n",
      "male,0,26,0\n",
      "male,0,7.75,0\n",
      "male,0,7.775,0\n",
      "female,1,8.5167,1\n",
      "male,0,22.525,0\n",
      "male,0,7.8208,0\n",
      "male,0,7.75,0\n",
      "male,0,8.7125,0\n",
      "male,0,13,0\n",
      "male,0,15.0458,0\n",
      "female,0,7.7792,1\n",
      "female,0,31.6792,1\n",
      "female,0,7.2833,1\n",
      "female,0,221.7792,1\n",
      "male,0,14.4542,0\n",
      "male,0,6.4375,0\n",
      "female,1,16.7,1\n",
      "male,0,75.2417,0\n",
      "female,0,26,1\n",
      "female,0,15.75,1\n",
      "male,0,7.75,0\n",
      "female,0,57.75,1\n",
      "male,0,7.25,0\n",
      "male,0,7.75,0\n",
      "female,1,16.1,1\n",
      "male,0,7.7958,0\n",
      "female,0,23.25,1\n",
      "male,0,13,0\n",
      "male,0,8.05,0\n",
      "male,0,8.05,0\n",
      "male,0,28.5,0\n",
      "female,4,25.4667,1\n",
      "male,0,6.4375,0\n",
      "male,0,7.8958,0\n",
      "male,0,7.8542,0\n",
      "male,0,7.225,0\n",
      "male,0,13,0\n",
      "female,0,8.05,1\n",
      "male,6,46.9,0\n",
      "female,2,46.9,1\n",
      "female,0,151.55,1\n",
      "male,3,262.375,0\n",
      "male,0,26,0\n",
      "male,0,26.55,0\n",
      "male,0,18,0\n",
      "male,0,51.8625,0\n",
      "male,0,8.05,0\n",
      "male,0,26.55,0\n",
      "male,1,26,0\n",
      "female,1,83.1583,1\n",
      "male,0,7.8958,0\n",
      "male,0,,0\n",
      "female,2,12.1833,1\n",
      "male,2,31.3875,0\n",
      "male,0,7.55,0\n",
      "female,0,221.7792,1\n",
      "female,0,7.8542,1\n",
      "male,0,26.55,0\n",
      "female,2,13.775,1\n",
      "female,0,7.7333,1\n",
      "male,1,15.2458,0\n",
      "female,0,13.5,1\n",
      "male,0,7,0\n",
      "male,0,13,0\n",
      "female,1,22.025,1\n",
      "male,0,50.4958,0\n",
      "male,2,34.375,0\n",
      "female,0,27.7208,1\n",
      "female,0,8.9625,1\n",
      "male,0,7.55,0\n",
      "male,0,7.225,0\n",
      "male,0,13.9,0\n",
      "male,0,7.2292,0\n",
      "male,5,31.3875,0\n",
      "female,2,39,1\n",
      "female,0,36.75,1\n",
      "male,0,55.4417,0\n",
      "female,3,39,1\n",
      "female,2,83.1583,1\n",
      "male,0,13,0\n",
      "male,1,83.1583,0\n",
      "female,0,53.1,1\n",
      "male,0,7.75,0\n",
      "female,1,247.5208,1\n",
      "male,0,16,0\n",
      "female,1,21,1\n",
      "male,0,8.05,0\n",
      "female,2,69.55,1\n",
      "male,0,13,0\n",
      "male,0,26,0\n",
      "male,0,26,0\n",
      "male,1,14.5,0\n",
      "male,0,12.35,0\n",
      "male,2,32.5,0\n",
      "male,0,7.8542,0\n",
      "male,2,134.5,0\n",
      "female,0,7.775,1\n",
      "male,0,10.5,0\n",
      "female,0,8.1125,1\n",
      "female,0,15.5,1\n",
      "male,2,14.4,0\n",
      "male,0,227.525,1\n",
      "female,1,26,1\n",
      "male,0,10.5,0\n",
      "male,0,25.7417,0\n",
      "female,0,7.75,1\n",
      "male,0,10.5,0\n",
      "female,0,27.7208,1\n",
      "male,0,7.8958,0\n",
      "male,0,22.525,0\n",
      "male,0,7.05,0\n",
      "male,0,73.5,0\n",
      "female,0,26,1\n",
      "female,2,7.775,1\n",
      "male,0,42.5,0\n",
      "female,0,7.8792,1\n",
      "male,1,164.8667,0\n",
      "female,1,211.5,1\n",
      "male,0,8.05,0\n",
      "female,0,13.8583,1\n",
      "male,0,8.05,0\n",
      "female,0,10.5,1\n",
      "male,0,7.7958,0\n",
      "female,0,27.4458,1\n",
      "female,2,15.2458,1\n",
      "male,0,7.7958,0\n",
      "female,0,7.75,1\n",
      "male,0,15.1,0\n",
      "male,0,13,0\n",
      "male,0,65,0\n",
      "female,0,26.55,1\n",
      "male,0,6.4958,0\n",
      "male,0,7.8792,0\n",
      "male,0,71.2833,0\n",
      "male,0,7.8542,0\n",
      "male,0,75.25,0\n",
      "male,0,7.225,0\n",
      "female,1,13,1\n",
      "female,0,106.425,1\n",
      "female,0,27.7208,1\n",
      "female,2,30,1\n",
      "male,1,134.5,0\n",
      "male,0,7.8875,0\n",
      "male,2,23.45,0\n",
      "male,0,51.8625,0\n",
      "female,0,21,1\n",
      "male,1,32.5,0\n",
      "female,0,26,1\n",
      "female,0,14.4542,1\n",
      "female,2,27.75,1\n",
      "male,0,7.925,0\n",
      "male,0,136.7792,0\n",
      "male,0,9.325,0\n",
      "male,0,9.5,0\n",
      "male,0,7.55,0\n",
      "male,0,7.75,0\n",
      "male,0,8.05,0\n",
      "female,0,13,1\n",
      "male,0,7.775,0\n",
      "male,0,17.4,0\n",
      "male,0,7.8542,0\n",
      "female,2,23,1\n",
      "female,1,12.1833,1\n",
      "male,0,12.7375,0\n",
      "male,0,7.8958,0\n",
      "male,0,0,0\n",
      "male,0,7.55,0\n",
      "female,0,8.05,1\n",
      "male,0,8.6625,0\n",
      "male,0,75.2417,0\n",
      "male,0,7.75,0\n",
      "female,0,136.7792,1\n",
      "female,0,15.5,1\n",
      "male,0,7.225,0\n",
      "female,0,26,1\n",
      "male,0,10.5,0\n",
      "male,0,26,0\n",
      "male,0,21,0\n",
      "male,0,10.5,0\n",
      "female,0,8.6625,1\n",
      "male,1,13.775,0\n",
      "female,0,7.75,1\n",
      "female,1,15.2458,1\n",
      "female,1,20.2125,1\n",
      "male,0,7.25,0\n",
      "male,0,7.25,0\n",
      "male,0,82.2667,0\n",
      "male,0,7.2292,0\n",
      "male,0,8.05,0\n",
      "male,0,39.6,0\n",
      "female,0,6.95,1\n",
      "male,0,7.2292,0\n",
      "male,1,81.8583,0\n",
      "male,0,9.5,0\n",
      "male,0,7.8958,0\n",
      "female,2,41.5792,1\n",
      "male,0,21.6792,0\n",
      "male,0,45.5,0\n",
      "male,0,7.8542,0\n",
      "male,0,7.775,0\n",
      "male,0,15.0458,0\n",
      "male,1,21,0\n",
      "male,0,8.6625,0\n",
      "female,0,7.75,1\n",
      "female,1,26.55,1\n",
      "male,2,151.55,0\n",
      "male,1,9.35,0\n",
      "male,1,93.5,0\n",
      "female,0,14.1083,1\n",
      "male,0,8.6625,0\n",
      "male,0,7.225,0\n",
      "male,0,7.575,0\n",
      "female,0,7.75,1\n",
      "female,0,135.6333,1\n",
      "female,0,7.7333,1\n",
      "male,0,146.5208,0\n",
      "male,0,10.5,0\n",
      "male,0,7.8542,0\n",
      "male,0,31.5,0\n",
      "male,0,7.775,0\n",
      "male,0,7.2292,0\n",
      "male,0,13,0\n",
      "male,0,26.55,0\n",
      "female,0,211.3375,1\n",
      "male,0,7.05,0\n",
      "female,1,39,1\n",
      "male,0,79.2,0\n",
      "male,0,26,0\n",
      "male,0,13,0\n",
      "female,2,36.75,1\n",
      "male,0,29.7,0\n",
      "male,0,7.225,0\n",
      "female,1,15.7417,1\n",
      "male,0,7.8958,0\n",
      "male,0,26,0\n",
      "male,0,13,0\n",
      "male,2,7.2292,0\n",
      "male,0,31.5,0\n",
      "male,0,7.2292,0\n",
      "male,0,10.5,0\n",
      "male,0,7.5792,0\n",
      "male,9,69.55,0\n",
      "female,1,512.3292,1\n",
      "male,1,14.5,0\n",
      "female,0,7.65,1\n",
      "male,0,13,0\n",
      "female,0,7.2292,1\n",
      "male,0,13.5,0\n",
      "female,0,21,1\n",
      "female,1,63.3583,1\n",
      "male,0,10.5,0\n",
      "male,0,73.5,0\n",
      "male,2,65,0\n",
      "female,2,20.575,1\n",
      "male,0,26,0\n",
      "female,0,51.4792,1\n",
      "male,0,7.8792,0\n",
      "male,0,7.75,0\n",
      "female,0,15.55,1\n",
      "male,2,69.55,0\n",
      "female,1,37.0042,1\n",
      "female,0,21,1\n",
      "male,0,8.6625,0\n",
      "female,0,55.4417,1\n",
      "female,9,69.55,0\n",
      "male,0,14.4583,0\n",
      "female,0,39.6875,1\n",
      "female,1,59.4,1\n",
      "male,0,13.8583,0\n",
      "male,0,11.5,0\n",
      "female,0,134.5,1\n",
      "male,0,0,0\n",
      "male,0,13,0\n",
      "female,1,81.8583,1\n",
      "female,0,262.375,1\n",
      "female,0,8.6625,1\n",
      "male,0,11.5,0\n",
      "male,0,50,0\n",
      "male,2,31.3875,0\n",
      "male,0,7.75,0\n",
      "male,0,7.8792,0\n",
      "female,0,14.5,1\n",
      "female,0,16.1,1\n",
      "male,0,12.875,0\n",
      "female,2,65,1\n",
      "male,0,7.775,0\n",
      "male,0,13,0\n",
      "male,0,7.75,0\n",
      "male,1,21.075,0\n",
      "male,0,93.5,0\n",
      "female,1,39.4,1\n",
      "male,2,20.25,0\n",
      "male,0,10.5,0\n",
      "male,1,22.025,0\n",
      "female,0,60,1\n",
      "male,0,7.25,0\n",
      "female,1,79.2,1\n",
      "male,0,7.775,0\n",
      "male,0,7.7333,0\n",
      "female,0,164.8667,1\n",
      "male,0,21,0\n",
      "female,1,59.4,1\n",
      "male,0,47.1,0\n",
      "male,0,27.7208,0\n",
      "male,0,13.8625,0\n",
      "male,0,10.5,0\n",
      "male,1,211.5,0\n",
      "female,0,7.7208,1\n",
      "female,1,13.775,1\n",
      "female,0,7.75,1\n",
      "female,0,90,1\n",
      "female,0,7.775,1\n",
      "male,0,8.05,0\n",
      "female,0,108.9,1\n",
      "male,0,7.25,0\n",
      "male,0,8.05,0\n",
      "male,1,22.3583,0\n"
     ]
    }
   ],
   "source": [
    "! python3 vis_titanic_mod.py titanic_test.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your current directory should now have a png called 'titanic_visual.png' in it that looks like the following: \n",
    "![titanic_visual](titanic_visual.png \"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see the 2D hidden space that corresponds to the two neurons the model uses. We can see a clear plane separating the two classifications. This is the plane that the predictor uses to distinguish between the two classes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}