{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Breast Cancer Data Prediction Using Daimensions\n",
    "\n",
    "In this notebook, we'll be working with a dataset from the University of California Irvine's Machine Learning Repository. It has nine attribute columns to describe various aspects of cells and one classification column that classifies each cell as benign or malignant cancer. More information about the data can be found at: https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic).\n",
    "\n",
    "We have two goals: one is to build a model predicting whether a cell is benign or malignant on future cell data and the other is to use attribute rank to learn about which attributes of the cell are most important for predicting cancer in cells. Daimensions' attribute rank option is useful for a lot of biomedical data like cancer cells because most of the time we are not only looking to predict which cells are cancerous but also what caused the cancer. Attribute rank helps us learn about this aspect of the data by telling us which attributes most closely correlate with a cell's classification. This greatly contributes to our understanding of the data and helps guide us toward probable cause.\n",
    "\n",
    "Here is a look at our training data and the attributes we're using. For the target column, 2 is benign and 4 is malignant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "! cancer_train.csv | more\n# For Windows command prompt:\n# type cancer_train.csv | more\n"
     },
     "metadata": {}
    }
   ],
   "source": [
    "%%markdown\n",
    "! cancer_train.csv | more\n",
    "# For Windows command prompt:\n",
    "# type cancer_train.csv | more"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Get Measurements\n",
    "\n",
    "We always want to measure our data before building our predictor in order to ensure we are building the right model. For more information about how to use Daimensions and why we want to measure our data beforehand, check out the Titanic notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nBrainome Daimensions(tm) 0.991 Copyright (c) 2019, 2020 by Brainome, Inc. All Rights Reserved.\nExpiration date: 2021-04-30 (66 days left)\nNumber of threads: 1\nMaximum file size: 30720MB\nRunning locally.\nWARNING: Could not detect a GPU. Neural Network generation will be slow.\n\nData:\nNumber of instances: 559\nNumber of attributes: 9\nNumber of classes: 2\nClass balance: 63.15% 36.85%\n\nLearnability:\nBest guess accuracy: 63.15%\nCapacity progression: [4, 5, 5, 5, 7, 7]\nDecision Tree: 12 parameters\nEstimate Memory Equivalent Capacity for Random Forests: 16 parameters\nEstimated Memory Equivalent Capacity for Neural Networks: 56 parameters\n\nRisk that model needs to overfit for 100% accuracy...\nusing Decision Tree: 4.70%\nusing Random Forests: 3.12%\nusing Neural Networks: 56.00%\n\nExpected Generalization...\nusing Decision Tree: 43.36 bits/bit\nusing Random Forests: 34.94 bits/bit\nusing a Neural Network: 9.48 bits/bit\n\nRecommendations:\nNote: Maybe enough data to generalize. [yellow]\nNote: Decision Tree clustering may outperform Neural Networks. Try with -f DT.\nWarning: Remapped class labels to be contiguous. Use -cm if DET/ROC-based accuracy measurements are wrong.\nTime estimate for a Neural Network:\nEstimated time to architect: 0d 0h 0m 0s\n\nEstimated time to prime (subject to change after model architecting): 0d 0h 0m 50s\n\nTime estimate for Decision Tree:\nEstimated time to prime a decision tree: a few seconds\n\n"
     ]
    }
   ],
   "source": [
    "! btc.bat -measureonly cancer_train.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build the Predictor\n",
    "\n",
    "Based on our measurements, Daimensions recommends we use a decision tree, which has lower risk of overfit and higher generalization for this dataset. We are also using -rank to prioritize certain attributes from our data, and we'll look at which attributes Daimensions decides are important later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Brainome Daimensions(tm) 0.991 Copyright (c) 2019, 2020 by Brainome, Inc. All Rights Reserved.\nExpiration date: 2021-04-30 (66 days left)\nNumber of threads: 1\nMaximum file size: 30720MB\nRunning locally.\nWARNING: Could not detect a GPU. Neural Network generation will be slow.\n\nInput: cancer_train.csv\nSampling...done.\nCleaning...done.\nNote: Class labels required remapping onto contiguous integers. Mapped as follows: {'2': 0, '4': 1}\nRanking attributes...done.\nSplitting into training and validation...done.\nPre-training measurements...done.\n\nAttribute Ranking:\nUsing only the important columns: Uniformity_of_Cell_Shape Bare_Nuclei Clump_Thickness Normal_Nucleoli Uniformity_of_Cell_Size\nRisk of coincidental column correlation: <0.001%\n\nData:\nNumber of instances: 559\nNumber of attributes: 5\nNumber of classes: 2\nClass balance: 63.15% 36.85%\n\nLearnability:\nBest guess accuracy: 63.15%\nCapacity progression: [3, 5, 6, 6, 6, 8]\nDecision Tree: 5 parameters\nEstimate Memory Equivalent Capacity for Random Forests: 8 parameters\nEstimated Memory Equivalent Capacity for Neural Networks: 36 parameters\n\nRisk that model needs to overfit for 100% accuracy...\nusing Decision Tree: 1.97%\nusing Random Forests: 1.56%\nusing Neural Networks: 56.25%\n\nExpected Generalization...\nusing Decision Tree: 103.31 bits/bit\nusing Random Forests: 69.88 bits/bit\nusing a Neural Network: 14.74 bits/bit\n\nRecommendations:\nWarning: Not enough data to generalize. [red]\nNote: Decision Tree clustering may outperform Neural Networks. Try with -f DT.\nWarning: Remapped class labels to be contiguous. Use -cm if DET/ROC-based accuracy measurements are wrong.\nTime estimate for Decision Tree:\nEstimated time to prime a decision tree: a few seconds\nNote: Machine learner type DT given by user.\nBuilding classifier...done.\nEstimated time to train a decision tree: less than a minute\nTraining...done.\nCompiling predictor...done.\nValidating predictor...done.\nClassifier Type:                    Decision Tree\nSystem Type:                         Binary classifier\nTraining/Validation Split:           60:40%\nBest-guess accuracy:                 63.14%\nTraining accuracy:                   97.01% (325/335 correct)\nValidation accuracy:                 97.76% (219/224 correct)\nOverall Model accuracy:              97.31% (544/559 correct)\nOverall Improvement over best guess: 34.17% (of possible 36.86%)\nModel capacity (MEC):                5 bits\nGeneralization ratio:                62.09 bits/bit\nModel efficiency:                    6.83%/parameter\nSystem behavior\nTrue Negatives:                      61.00% (341/559)\nTrue Positives:                      36.31% (203/559)\nFalse Negatives:                     0.54% (3/559)\nFalse Positives:                     2.15% (12/559)\nTrue Pos. Rate/Sensitivity/Recall:   0.99\nTrue Neg. Rate/Specificity:          0.97\nPrecision:                           0.94\nF-1 Measure:                         0.96\nFalse Negative Rate/Miss Rate:       0.01\nCritical Success Index:              0.93\nConfusion Matrix:\n [61.00% 2.15%]\n [0.54% 36.31%]\nGeneralization index:           30.44\nOverfitting:                         No\nNote: Labels have been remapped to '2'=0, '4'=1.\nUsing only the important columns: Uniformity_of_Cell_Shape Bare_Nuclei Clump_Thickness Normal_Nucleoli Uniformity_of_Cell_Size\nRisk of coincidental column correlation: <0.001%\n\n\nOutput: cancer_predict.py\nREADY.\n"
     ]
    }
   ],
   "source": [
    "! btc -v -v -f DT cancer_train.csv -o cancer_predict.py -e 10 -rank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Validate the Model\n",
    "\n",
    "Now we can validate our model on a separate set of data that wasn't used for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Classifier Type:                    Decision Tree\nSystem Type:                        Binary classifier\nBest-guess accuracy:                75.00%\nModel accuracy:                     99.28% (139/140 correct)\nImprovement over best guess:        24.28% (of possible 25.0%)\nModel capacity (MEC):               5 bits\nGeneralization ratio:               22.55 bits/bit\nModel efficiency:                   4.85%/parameter\nSystem behavior\nTrue Negatives:                     74.29% (104/140)\nTrue Positives:                     25.00% (35/140)\nFalse Negatives:                    0.00% (0/140)\nFalse Positives:                    0.71% (1/140)\nTrue Pos. Rate/Sensitivity/Recall:  1.00\nTrue Neg. Rate/Specificity:         0.99\nPrecision:                          0.97\nF-1 Measure:                        0.99\nFalse Negative Rate/Miss Rate:      0.00\nCritical Success Index:             0.97\nNote: If you install scipy (https://www.scipy.org) this predictor generates a confusion matrix\n\n"
     ]
    }
   ],
   "source": [
    "! python3 cancer_predict.py -validate cancer_valid.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Learn From Attribute Rank\n",
    "\n",
    "From validating the data, we can see that the predictor has 99.28% accuracy. This is great for making predictions on future data. However, what might be of greater interest is looking at the output from building our predictor, specifically the attributes that Daimensions decided to use. Under the section of output called \"Attribute Rank,\" Daimensions has listed the attributes used: Uniformity_of_Cell_Size, Bare_Nuclei, Clump_Thickness, Marginal_Adhesion, Mitoses, and Uniformity_of_Cell_Shape. This information about what attributes were the best predictors of malignant cancer cells is valuable to scientists looking for the causes of this cancer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Citation\n",
    "This breast cancer databases was obtained from the University of Wisconsin Hospitals, Madison from Dr. William H. Wolberg.\n",
    "\n",
    "Sources:\n",
    "- Dr. WIlliam H. Wolberg (physician), University of Wisconsin Hospitals, Madison, Wisconsin, USA\n",
    "- Donor: Olvi Mangasarian (mangasarian@cs.wisc.edu), received by David W. Aha (aha@cs.jhu.edu)\n",
    "- Date: 15 July 1992"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}