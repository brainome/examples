{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Data Prediction Using Daimensions\n",
    "\n",
    "MNIST is a well-known dataset of handwritten digits and a standard for machine learning models. Here, we test how Daimensions does on it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Setup\n",
    "\n",
    "We'll get the csv from the OpenML link and use a pandas dataframe to split it into training and validation data in csv's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>pixel10</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>70000.0</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>70000.000000</td>\n",
       "      <td>70000.000000</td>\n",
       "      <td>70000.000000</td>\n",
       "      <td>70000.000000</td>\n",
       "      <td>70000.000000</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>70000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.099543</td>\n",
       "      <td>0.046629</td>\n",
       "      <td>0.016614</td>\n",
       "      <td>0.012957</td>\n",
       "      <td>0.001714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.452429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.256304</td>\n",
       "      <td>2.783732</td>\n",
       "      <td>1.561822</td>\n",
       "      <td>1.553796</td>\n",
       "      <td>0.320889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.890195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>253.000000</td>\n",
       "      <td>253.000000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        pixel1   pixel2   pixel3   pixel4   pixel5   pixel6   pixel7   pixel8  \\\n",
       "count  70000.0  70000.0  70000.0  70000.0  70000.0  70000.0  70000.0  70000.0   \n",
       "mean       0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "std        0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "min        0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "25%        0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "50%        0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "75%        0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "max        0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "        pixel9  pixel10  ...      pixel776      pixel777      pixel778  \\\n",
       "count  70000.0  70000.0  ...  70000.000000  70000.000000  70000.000000   \n",
       "mean       0.0      0.0  ...      0.099543      0.046629      0.016614   \n",
       "std        0.0      0.0  ...      4.256304      2.783732      1.561822   \n",
       "min        0.0      0.0  ...      0.000000      0.000000      0.000000   \n",
       "25%        0.0      0.0  ...      0.000000      0.000000      0.000000   \n",
       "50%        0.0      0.0  ...      0.000000      0.000000      0.000000   \n",
       "75%        0.0      0.0  ...      0.000000      0.000000      0.000000   \n",
       "max        0.0      0.0  ...    254.000000    253.000000    253.000000   \n",
       "\n",
       "           pixel779      pixel780  pixel781  pixel782  pixel783  pixel784  \\\n",
       "count  70000.000000  70000.000000   70000.0   70000.0   70000.0   70000.0   \n",
       "mean       0.012957      0.001714       0.0       0.0       0.0       0.0   \n",
       "std        1.553796      0.320889       0.0       0.0       0.0       0.0   \n",
       "min        0.000000      0.000000       0.0       0.0       0.0       0.0   \n",
       "25%        0.000000      0.000000       0.0       0.0       0.0       0.0   \n",
       "50%        0.000000      0.000000       0.0       0.0       0.0       0.0   \n",
       "75%        0.000000      0.000000       0.0       0.0       0.0       0.0   \n",
       "max      254.000000     62.000000       0.0       0.0       0.0       0.0   \n",
       "\n",
       "              class  \n",
       "count  70000.000000  \n",
       "mean       4.452429  \n",
       "std        2.890195  \n",
       "min        0.000000  \n",
       "25%        2.000000  \n",
       "50%        4.000000  \n",
       "75%        7.000000  \n",
       "max        9.000000  \n",
       "\n",
       "[8 rows x 785 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using pandas to get csv as a dataframe and see how it looks\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dataset_url = 'https://www.openml.org/data/get_csv/52667/mnist_784.csv'\n",
    "data = pd.read_csv(dataset_url)\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into training and testing csv's, y is for the target column (int0)\n",
    "y = data['class']\n",
    "X = data.drop('class', axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.2)\n",
    "pd.concat([X_train, y_train], axis=1).to_csv('mnist_train.csv',index=False)\n",
    "pd.concat([X_test, y_test], axis=1).to_csv('mnist_valid.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Get Measurements\n",
    "\n",
    "We always want to measure our data before building our predictor in order to ensure we are building the right model. For more information about how to use Daimensions and why we want to measure our data beforehand, check out the Titanic notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brainome Daimensions(tm) 0.97 Copyright (c) 2019, 2020 by Brainome, Inc. All Rights Reserved.\n",
      "Licensed to: Ariana Park\n",
      "Expiration date: 2020-11-30 (102 days left)\n",
      "Number of threads: 1\n",
      "Maximum file size: 4GB\n",
      "Connected to Brainome cloud.\n",
      "\n",
      "Data:\n",
      "Number of instances: 56000\n",
      "Number of attributes: 785\n",
      "Number of classes: 10\n",
      "Class balance: 9.91% 11.27% 9.97% 10.2% 9.7% 9.02% 9.81% 10.44% 9.71% 9.97%\n",
      "\n",
      "Learnability:\n",
      "Best guess accuracy: 11.27%\n",
      "Capacity progression (# of decision points): [14, 15, 16, 16, 17, 17]\n",
      "Decision Tree: 49973 parameters\n",
      "Estimated Memory Equivalent Capacity for Neural Networks: 12746 parameters\n",
      "\n",
      "Risk that model needs to overfit for 100% accuracy...\n",
      "using Decision Tree: 99.15%\n",
      "using Neural Networks: 100.00%\n",
      "\n",
      "Expected Generalization...\n",
      "using Decision Tree: 1.12 bits/bit\n",
      "using a Neural Network: 4.39 bits/bit\n",
      "\n",
      "Recommendations:\n",
      "Note: Maybe enough data to generalize. [yellow]\n",
      "Warning: Data has high information density. Expect varying results and increase --effort.\n",
      "Warning: Cannot find numpy. The output predictor may not run on this machine.\n",
      "\n",
      "Time estimate for a Neural Network:\n",
      "Estimated time to architect: 0d 0h 5m 36s\n",
      "Estimated time to prime (subject to change after model architecting): 1d 2h 15m 3s\n",
      "\n",
      "Time estimate for Decision Tree:\n",
      "Estimated time to prime a decision tree: less than a minute\n"
     ]
    }
   ],
   "source": [
    "! btc -measureonly mnist_train.csv "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build the Predictor\n",
    "\n",
    "Based on our measurements, Daimensions recommends we use a neural network (higher expected generalization) and more effort for this dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brainome Daimensions(tm) 0.97 Copyright (c) 2019, 2020 by Brainome, Inc. All Rights Reserved.\n",
      "Licensed to: Ariana Park\n",
      "Expiration date: 2020-11-30 (99 days left)\n",
      "Number of threads: 1\n",
      "Maximum file size: 4GB\n",
      "Connected to: https://beta.brainome.ai:8080\n",
      "\n",
      "Input: mnist_train.csv\n",
      "Sampling...\n",
      "Cleaning...\n",
      "Splitting into training and validation...done.\n",
      "Pre-training measurements...done.\n",
      "Data:\n",
      "Number of instances: 56000\n",
      "Number of attributes: 784\n",
      "Number of classes: 10\n",
      "Class balance: 9.79% 11.23% 9.96% 10.22% 9.87% 9.07% 9.83% 10.4% 9.63% 10.0%\n",
      "\n",
      "Learnability:\n",
      "Best guess accuracy: 11.23%\n",
      "Capacity progression (# of decision points): [14, 15, 16, 16, 17, 17]\n",
      "Decision Tree: 46671 parameters\n",
      "Estimated Memory Equivalent Capacity for Neural Networks: 12730 parameters\n",
      "\n",
      "Risk that model needs to overfit for 100% accuracy...\n",
      "using Decision Tree: 92.60%\n",
      "using Neural Networks: 100.00%\n",
      "\n",
      "Expected Generalization...\n",
      "using Decision Tree: 1.20 bits/bit\n",
      "using a Neural Network: 4.40 bits/bit\n",
      "\n",
      "Recommendations:\n",
      "Note: Maybe enough data to generalize. [yellow]\n",
      "Warning: Cannot find numpy. The output predictor may not run on this machine.\n",
      "\n",
      "Time estimate for a Neural Network:\n",
      "Estimated time to architect: 0d 0h 5m 6s\n",
      "Estimated time to prime (subject to change after model architecting): 1d 1h 44m 32s\n",
      "Note: Machine learner type NN given by user.\n",
      "Architecting model...done.\n",
      "Model capacity (MEC):     1075 bits\n",
      "Architecture efficiency:   1.0 bits/parameter\n",
      "\n",
      "Estimating time to prime model...done.\n",
      "Estimated time to prime model: 0d 1h 10m 22s\n",
      "\n",
      "Priming model...done.\n",
      "Estimating training time...done.\n",
      "Estimated training time: 0d 3h 36m 53s\n",
      "\n",
      "Training...done.\n",
      "Model created:\n",
      "Sequential(\n",
      "  (0): Linear(in_features=60, out_features=15, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=15, out_features=10, bias=True)\n",
      ")\n",
      "\n",
      "Compiling predictor...done.\n",
      "Validating predictor...done.\n",
      "Classifier Type:                    Neural Network\n",
      "System Type:                        10-way classifier\n",
      "Best-guess accuracy:                11.23%\n",
      "Model accuracy:                     68.28% (38239/56000 correct)\n",
      "Improvement over best guess:        57.05% (of possible 88.77%)\n",
      "Model capacity (MEC):               1075 bits\n",
      "Generalization ratio:               35.57 bits/bit\n",
      "Confusion Matrix:\n",
      " [8.04% 0.01% 0.07% 0.22% 0.05% 0.54% 0.77% 0.03% 0.05% 0.03%]\n",
      " [0.01% 10.37% 0.10% 0.11% 0.07% 0.41% 0.01% 0.03% 0.07% 0.04%]\n",
      " [0.43% 0.07% 6.75% 0.60% 0.39% 0.43% 0.78% 0.13% 0.35% 0.03%]\n",
      " [0.33% 0.40% 0.69% 5.88% 0.16% 1.17% 0.27% 0.12% 0.98% 0.23%]\n",
      " [0.10% 0.20% 0.20% 0.08% 6.45% 0.55% 0.45% 0.34% 0.32% 1.19%]\n",
      " [1.55% 0.47% 0.24% 0.88% 0.22% 3.90% 0.71% 0.05% 0.63% 0.43%]\n",
      " [1.22% 0.08% 0.61% 0.14% 0.14% 1.06% 6.40% 0.10% 0.07% 0.00%]\n",
      " [0.05% 0.13% 0.22% 0.18% 0.27% 0.21% 0.02% 8.28% 0.24% 0.81%]\n",
      " [0.35% 0.49% 0.40% 0.74% 0.08% 1.36% 0.21% 0.08% 5.36% 0.56%]\n",
      " [0.09% 0.40% 0.08% 0.17% 0.83% 0.40% 0.05% 0.74% 0.38% 6.85%]\n",
      "Overfitting:                        No\n",
      "\n",
      "Output: mnist_predict.py \n",
      "READY.\n"
     ]
    }
   ],
   "source": [
    "! btc -vvv -f NN mnist_train.csv -o mnist_predict.py -e 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Validate the Model\n",
    "\n",
    "Now we can validate our model on a separate set of data that wasn't used for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier Type:                    Neural Network\n",
      "System Type:                        10-way classifier\n",
      "Best-guess accuracy:                11.33%\n",
      "Model accuracy:                     68.15% (9542/14000 correct)\n",
      "Improvement over best guess:        56.82% (of possible 88.67%)\n",
      "Model capacity (MEC):               1075 bits\n",
      "Generalization ratio:               8.87 bits/bit\n",
      "Confusion Matrix:\n",
      " [8.26% 0.01% 0.06% 0.21% 0.06% 0.58% 0.82% 0.04% 0.05% 0.06%]\n",
      " [0.01% 10.56% 0.07% 0.09% 0.04% 0.42% 0.02% 0.03% 0.06% 0.02%]\n",
      " [0.48% 0.07% 6.72% 0.63% 0.54% 0.44% 0.76% 0.12% 0.28% 0.04%]\n",
      " [0.29% 0.36% 0.75% 5.97% 0.11% 1.15% 0.27% 0.11% 0.90% 0.21%]\n",
      " [0.08% 0.21% 0.21% 0.07% 6.07% 0.51% 0.41% 0.36% 0.34% 0.99%]\n",
      " [1.49% 0.45% 0.25% 0.81% 0.24% 3.71% 0.74% 0.04% 0.61% 0.46%]\n",
      " [1.29% 0.08% 0.54% 0.11% 0.16% 1.06% 6.45% 0.08% 0.04% 0.01%]\n",
      " [0.05% 0.15% 0.19% 0.13% 0.31% 0.20% 0.03% 8.33% 0.23% 0.86%]\n",
      " [0.41% 0.57% 0.37% 0.95% 0.10% 1.35% 0.17% 0.14% 5.51% 0.65%]\n",
      " [0.14% 0.38% 0.05% 0.20% 0.87% 0.27% 0.07% 0.84% 0.36% 6.56%]\n"
     ]
    }
   ],
   "source": [
    "! python3 mnist_predict.py -validate mnist_valid.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hooray! We've finished building our model and validating its accuracy. We also have the confusion matrix, which compares the actual target classes (columns) with the predicted class (rows). Diagonal values are correctly predicted values."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
