{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.3 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Best Model Selector for Phone Activity Classification\n",
    "In the following notebook, we are going to be using a dataset from the UCI Machine Learning Repository. The dataset has 561 attributes, which are all gyroscope measurements, and they are all standardized. Our goal is to classify the activity level on a scale from 1 to 6. More information about the dataset: https://www.apispreadsheets.com/datasets/122\n",
    "\n",
    "Here is some sample data from the dataset:\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "feature_1,feature_2,feature_3,feature_4,feature_5,feature_6,feature_7,feature_8,feature_9,feature_10,feature_11,feature_12,feature_13,feature_14,feature_15,feature_16,feature_17,feature_18,feature_19,feature_20,feature_21,feature_22,feature_23,feature_24,feature_25,feature_26,feature_27,feature_28,feature_29,feature_30,feature_31,feature_32,feature_33,feature_34,feature_35,feature_36,feature_37,feature_38,feature_39,feature_40,feature_41,feature_42,feature_43,feature_44,feature_45,feature_46,feature_47,feature_48,feature_49,feature_50,feature_51,feature_52,feature_53,feature_54,feature_55,feature_56,feature_57,feature_58,feature_59,feature_60,feature_61,feature_62,feature_63,feature_64,feature_65,feature_66,feature_67,feature_68,feature_69,feature_70,feature_71,feature_72,feature_73,feature_74,feature_75,feature_76,feature_77,feature_78,feature_79,feature_80,feature_81,feature_82,feature_83,feature_84,feature_85,feature_86,feature_87,feature_88,feature_89,feature_90,feature_91,feature_92,feature_93,feature_94,feature_95,feature_96,feature_97,feature_98,feature_99,feature_100,feature_101,feature_102,feature_103,feature_104,feature_105,feature_106,feature_107,feature_108,feature_109,feature_110,feature_111,feature_112,feature_113,feature_114,feature_115,feature_116,feature_117,feature_118,feature_119,feature_120,feature_121,feature_122,feature_123,feature_124,feature_125,feature_126,feature_127,feature_128,feature_129,feature_130,feature_131,feature_132,feature_133,feature_134,feature_135,feature_136,feature_137,feature_138,feature_139,feature_140,feature_141,feature_142,feature_143,feature_144,feature_145,feature_146,feature_147,feature_148,feature_149,feature_150,feature_151,feature_152,feature_153,feature_154,feature_155,feature_156,feature_157,feature_158,feature_159,feature_160,feature_161,feature_162,feature_163,feature_164,feature_165,feature_166,feature_167,feature_168,feature_169,feature_170,feature_171,feature_172,feature_173,feature_174,feature_175,feature_176,feature_177,feature_178,feature_179,feature_180,feature_181,feature_182,feature_183,feature_184,feature_185,feature_186,feature_187,feature_188,feature_189,feature_190,feature_191,feature_192,feature_193,feature_194,feature_195,feature_196,feature_197,feature_198,feature_199,feature_200,feature_201,feature_202,feature_203,feature_204,feature_205,feature_206,feature_207,feature_208,feature_209,feature_210,feature_211,feature_212,feature_213,feature_214,feature_215,feature_216,feature_217,feature_218,feature_219,feature_220,feature_221,feature_222,feature_223,feature_224,feature_225,feature_226,feature_227,feature_228,feature_229,feature_230,feature_231,feature_232,feature_233,feature_234,feature_235,feature_236,feature_237,feature_238,feature_239,feature_240,feature_241,feature_242,feature_243,feature_244,feature_245,feature_246,feature_247,feature_248,feature_249,feature_250,feature_251,feature_252,feature_253,feature_254,feature_255,feature_256,feature_257,feature_258,feature_259,feature_260,feature_261,feature_262,feature_263,feature_264,feature_265,feature_266,feature_267,feature_268,feature_269,feature_270,feature_271,feature_272,feature_273,feature_274,feature_275,feature_276,feature_277,feature_278,feature_279,feature_280,feature_281,feature_282,feature_283,feature_284,feature_285,feature_286,feature_287,feature_288,feature_289,feature_290,feature_291,feature_292,feature_293,feature_294,feature_295,feature_296,feature_297,feature_298,feature_299,feature_300,feature_301,feature_302,feature_303,feature_304,feature_305,feature_306,feature_307,feature_308,feature_309,feature_310,feature_311,feature_312,feature_313,feature_314,feature_315,feature_316,feature_317,feature_318,feature_319,feature_320,feature_321,feature_322,feature_323,feature_324,feature_325,feature_326,feature_327,feature_328,feature_329,feature_330,feature_331,feature_332,feature_333,feature_334,feature_335,feature_336,feature_337,feature_338,feature_339,feature_340,feature_341,feature_342,feature_343,feature_344,feature_345,feature_346,feature_347,feature_348,feature_349,feature_350,feature_351,feature_352,feature_353,feature_354,feature_355,feature_356,feature_357,feature_358,feature_359,feature_360,feature_361,feature_362,feature_363,feature_364,feature_365,feature_366,feature_367,feature_368,feature_369,feature_370,feature_371,feature_372,feature_373,feature_374,feature_375,feature_376,feature_377,feature_378,feature_379,feature_380,feature_381,feature_382,feature_383,feature_384,feature_385,feature_386,feature_387,feature_388,feature_389,feature_390,feature_391,feature_392,feature_393,feature_394,feature_395,feature_396,feature_397,feature_398,feature_399,feature_400,feature_401,feature_402,feature_403,feature_404,feature_405,feature_406,feature_407,feature_408,feature_409,feature_410,feature_411,feature_412,feature_413,feature_414,feature_415,feature_416,feature_417,feature_418,feature_419,feature_420,feature_421,feature_422,feature_423,feature_424,feature_425,feature_426,feature_427,feature_428,feature_429,feature_430,feature_431,feature_432,feature_433,feature_434,feature_435,feature_436,feature_437,feature_438,feature_439,feature_440,feature_441,feature_442,feature_443,feature_444,feature_445,feature_446,feature_447,feature_448,feature_449,feature_450,feature_451,feature_452,feature_453,feature_454,feature_455,feature_456,feature_457,feature_458,feature_459,feature_460,feature_461,feature_462,feature_463,feature_464,feature_465,feature_466,feature_467,feature_468,feature_469,feature_470,feature_471,feature_472,feature_473,feature_474,feature_475,feature_476,feature_477,feature_478,feature_479,feature_480,feature_481,feature_482,feature_483,feature_484,feature_485,feature_486,feature_487,feature_488,feature_489,feature_490,feature_491,feature_492,feature_493,feature_494,feature_495,feature_496,feature_497,feature_498,feature_499,feature_500,feature_501,feature_502,feature_503,feature_504,feature_505,feature_506,feature_507,feature_508,feature_509,feature_510,feature_511,feature_512,feature_513,feature_514,feature_515,feature_516,feature_517,feature_518,feature_519,feature_520,feature_521,feature_522,feature_523,feature_524,feature_525,feature_526,feature_527,feature_528,feature_529,feature_530,feature_531,feature_532,feature_533,feature_534,feature_535,feature_536,feature_537,feature_538,feature_539,feature_540,feature_541,feature_542,feature_543,feature_544,feature_545,feature_546,feature_547,feature_548,feature_549,feature_550,feature_551,feature_552,feature_553,feature_554,feature_555,feature_556,feature_557,feature_558,feature_559,feature_560,feature_561,activity\n0.289,-0.0203,-0.133,-0.995,-0.983,-0.914,-0.995,-0.983,-0.924,-0.935,-0.567,-0.744,0.853,0.686,0.814,-0.966,-1.0,-1.0,-0.995,-0.994,-0.988,-0.943,-0.408,-0.679,-0.602,0.929,-0.853,0.36,-0.0585,0.257,-0.225,0.264,-0.0952,0.279,-0.465,0.492,-0.191,0.376,0.435,0.661,0.963,-0.141,0.115,-0.985,-0.982,-0.878,-0.985,-0.984,-0.895,0.892,-0.161,0.125,0.977,-0.123,0.0565,-0.375,0.899,-0.971,-0.976,-0.984,-0.989,-0.918,-1.0,-1.0,0.114,-0.59,0.591,-0.592,0.592,-0.745,0.721,-0.712,0.711,-0.995,0.996,-0.996,0.992,0.57,0.439,0.987,0.078,0.005,-0.0678,-0.994,-0.988,-0.994,-0.994,-0.986,-0.993,-0.985,-0.992,-0.993,0.99,0.992,0.991,-0.994,-1.0,-1.0,-1.0,-0.994,-0.986,-0.989,-0.82,-0.793,-0.889,1.0,-0.221,0.637,0.388,0.241,-0.0523,0.264,0.373,0.342,-0.57,0.265,-0.478,-0.385,0.0336,-0.127,-0.0061,-0.0314,0.108,-0.985,-0.977,-0.992,-0.985,-0.976,-0.992,-0.867,-0.934,-0.748,0.847,0.915,0.831,-0.967,-1.0,-0.999,-1.0,-0.983,-0.979,-0.993,0.0826,0.202,-0.169,0.0963,-0.275,0.499,-0.22,1.0,-0.973,0.317,0.376,0.723,-0.771,0.69,-0.332,0.71,0.135,0.301,-0.0992,-0.0555,-0.062,-0.992,-0.993,-0.992,-0.992,-0.995,-0.993,-0.99,-0.987,-0.992,0.994,0.992,0.989,-0.994,-1.0,-1.0,-1.0,-0.992,-0.997,-0.992,-0.59,-0.688,-0.572,0.292,-0.362,0.406,-0.039,0.989,-0.415,0.392,0.282,0.927,-0.572,0.692,0.468,-0.131,-0.0872,0.336,-0.959,-0.951,-0.958,-0.946,-0.993,-0.959,-0.998,-0.958,-0.233,-0.173,-0.0229,0.0948,0.192,-0.959,-0.951,-0.958,-0.946,-0.993,-0.959,-0.998,-0.958,-0.233,-0.173,-0.0229,0.0948,0.192,-0.993,-0.994,-0.995,-0.993,-0.991,-0.993,-1.0,-0.993,-0.863,0.283,-0.237,-0.105,-0.0382,-0.969,-0.964,-0.957,-0.975,-0.992,-0.969,-0.999,-0.95,0.0726,0.573,-0.739,0.213,0.433,-0.994,-0.991,-0.993,-0.989,-0.993,-0.994,-1.0,-0.995,-0.62,0.293,-0.177,-0.146,-0.124,-0.995,-0.983,-0.939,-0.995,-0.983,-0.906,-0.997,-0.985,-0.932,-0.994,-0.983,-0.885,-0.994,-0.993,-0.923,-0.975,-1.0,-1.0,-0.995,-0.996,-0.99,-0.988,-0.946,-0.905,-0.591,-1.0,-1.0,-1.0,0.252,0.132,-0.0521,0.142,-0.151,-0.221,-0.559,0.247,-0.00742,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-0.999,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-0.994,-0.999,-1.0,-1.0,-0.999,-0.998,-0.996,-0.995,-0.995,-1.0,-0.999,-0.996,-0.995,-0.999,-0.992,-0.987,-0.99,-0.996,-0.991,-0.997,-0.994,-0.991,-0.997,-0.997,-0.992,-0.993,-0.998,-0.991,-0.96,-0.991,-1.0,-1.0,-1.0,-0.993,-0.991,-0.996,-1.0,-1.0,-1.0,1.0,-0.24,-1.0,0.87,0.211,0.264,-0.704,-0.904,-0.583,-0.936,-0.507,-0.806,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-0.999,-1.0,-1.0,-1.0,-1.0,-0.999,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-0.999,-1.0,-1.0,-1.0,-1.0,-1.0,-0.999,-0.999,-1.0,-1.0,-1.0,-0.999,-1.0,-1.0,-0.987,-0.982,-0.99,-0.985,-0.974,-0.994,-0.987,-0.984,-0.992,-0.98,-0.972,-0.995,-0.998,-0.984,-0.994,-0.985,-1.0,-1.0,-1.0,-0.99,-0.995,-0.994,-0.712,-0.645,-0.839,-1.0,-1.0,-1.0,-0.258,0.0979,0.547,0.377,0.134,0.273,-0.0913,-0.484,-0.783,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-0.999,-1.0,-1.0,-1.0,-1.0,-1.0,-0.998,-0.999,-1.0,-1.0,-1.0,-0.998,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-0.999,-1.0,-1.0,-1.0,-1.0,-0.999,-1.0,-1.0,-0.952,-0.956,-0.949,-0.974,-0.926,-0.952,-0.998,-0.973,-0.646,-0.793,-0.0884,-0.436,-0.797,-0.994,-0.994,-0.992,-0.993,-0.988,-0.994,-1.0,-0.991,-1.0,-0.937,0.347,-0.516,-0.803,-0.98,-0.961,-0.974,-0.952,-0.989,-0.98,-0.999,-0.993,-0.701,-1.0,-0.129,0.586,0.375,-0.992,-0.991,-0.99,-0.992,-0.991,-0.992,-1.0,-0.99,-0.871,-1.0,-0.0743,-0.299,-0.71,-0.113,0.0304,-0.465,-0.0184,-0.841,0.18,-0.0586,5\n0.278,-0.0164,-0.124,-0.998,-0.975,-0.96,-0.999,-0.975,-0.958,-0.943,-0.558,-0.818,0.849,0.686,0.823,-0.982,-1.0,-1.0,-0.998,-0.999,-0.978,-0.948,-0.715,-0.501,-0.571,0.612,-0.33,0.284,0.285,0.116,-0.091,0.294,-0.281,0.086,-0.0222,-0.0167,-0.221,-0.0134,-0.0727,0.579,0.967,-0.142,0.109,-0.997,-0.989,-0.932,-0.998,-0.99,-0.933,0.892,-0.161,0.123,0.985,-0.115,0.103,-0.383,0.908,-0.971,-0.979,-0.999,-0.99,-0.942,-1.0,-1.0,-0.21,-0.41,0.414,-0.418,0.421,-0.196,0.125,-0.106,0.109,-0.834,0.834,-0.834,0.83,-0.831,-0.866,0.974,0.074,0.00577,0.0294,-0.996,-0.981,-0.992,-0.996,-0.979,-0.991,-0.995,-0.979,-0.992,0.993,0.992,0.989,-0.991,-1.0,-1.0,-1.0,-0.994,-0.979,-0.993,-0.875,-0.655,-0.767,0.49,0.071,0.363,0.527,0.149,0.0629,0.37,0.414,0.122,0.181,0.0474,0.167,-0.209,0.0841,-0.269,-0.0161,-0.0839,0.101,-0.983,-0.989,-0.989,-0.987,-0.989,-0.989,-0.865,-0.954,-0.746,0.834,0.908,0.829,-0.981,-1.0,-1.0,-1.0,-0.993,-0.989,-0.99,0.00747,-0.531,-0.177,-0.388,0.179,0.211,-0.14,-0.047,-0.0649,0.118,0.0817,0.0424,-0.15,0.293,-0.149,0.0467,-0.257,0.169,-0.111,-0.0448,-0.0592,-0.99,-0.997,-0.994,-0.99,-0.997,-0.994,-0.992,-0.998,-0.995,0.99,0.997,0.995,-0.995,-1.0,-1.0,-1.0,-0.991,-0.997,-0.994,-0.601,-0.748,-0.609,-0.193,-0.0674,0.186,0.0415,0.0724,-0.0354,0.178,0.0275,0.183,-0.167,0.253,0.132,0.294,-0.0181,-0.343,-0.979,-0.976,-0.978,-0.979,-0.995,-0.979,-0.999,-0.981,-0.442,0.0816,-0.109,0.312,-0.412,-0.979,-0.976,-0.978,-0.979,-0.995,-0.979,-0.999,-0.981,-0.442,0.0816,-0.109,0.312,-0.412,-0.991,-0.992,-0.993,-0.989,-0.991,-0.991,-1.0,-0.993,-0.82,0.459,-0.245,0.0561,-0.458,-0.981,-0.984,-0.982,-0.985,-0.992,-0.981,-1.0,-0.983,-0.193,-0.225,-0.0171,0.156,0.0826,-0.995,-0.996,-0.996,-0.997,-0.992,-0.995,-1.0,-0.995,-0.731,0.209,-0.178,-0.103,-0.0438,-0.997,-0.977,-0.974,-0.999,-0.975,-0.955,-0.998,-0.977,-0.968,-0.999,-0.974,-0.949,-0.998,-0.993,-0.99,-0.986,-1.0,-0.999,-0.999,-0.995,-0.981,-0.986,-1.0,-0.905,-0.758,0.0968,-1.0,-1.0,0.271,0.0429,-0.0143,-0.693,-0.954,-0.0497,-0.332,0.0567,-0.289,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-0.999,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-0.999,-1.0,-1.0,-1.0,-0.999,-1.0,-0.998,-1.0,-1.0,-1.0,-1.0,-0.999,-0.999,-0.999,-0.999,-1.0,-1.0,-0.999,-0.999,-1.0,-0.995,-0.981,-0.99,-0.997,-0.982,-0.993,-0.995,-0.983,-0.992,-0.997,-0.985,-0.993,-0.998,-0.983,-0.987,-0.99,-1.0,-1.0,-1.0,-0.993,-0.985,-0.991,-1.0,-1.0,-1.0,-0.32,-0.12,-0.32,0.609,-0.0537,0.0631,-0.63,-0.91,-0.414,-0.851,-0.656,-0.916,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-0.999,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-0.977,-0.993,-0.99,-0.985,-0.987,-0.99,-0.979,-0.992,-0.988,-0.987,-0.985,-0.99,-0.987,-0.999,-0.994,-0.987,-1.0,-1.0,-1.0,-0.987,-0.996,-0.987,-0.611,-0.765,-0.751,-1.0,-1.0,-1.0,-0.0482,-0.402,-0.0682,-0.459,-0.797,0.388,0.149,-0.157,-0.452,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-0.981,-0.976,-0.976,-0.978,-0.987,-0.981,-0.999,-0.984,-0.817,-1.0,-0.0441,-0.122,-0.45,-0.99,-0.992,-0.99,-0.994,-0.99,-0.99,-1.0,-0.991,-1.0,-0.841,0.532,-0.625,-0.9,-0.988,-0.983,-0.983,-0.986,-0.992,-0.988,-1.0,-0.994,-0.721,-0.949,-0.272,-0.336,-0.72,-0.996,-0.996,-0.995,-0.997,-0.994,-0.996,-1.0,-0.995,-1.0,-1.0,0.158,-0.595,-0.861,0.0535,-0.00743,-0.733,0.704,-0.845,0.18,-0.0543,5\n0.28,-0.0195,-0.113,-0.995,-0.967,-0.979,-0.997,-0.964,-0.977,-0.939,-0.558,-0.818,0.844,0.682,0.839,-0.983,-1.0,-1.0,-0.999,-0.997,-0.965,-0.975,-0.592,-0.486,-0.571,0.273,-0.0863,0.337,-0.165,0.0172,-0.0745,0.342,-0.333,0.239,-0.136,0.174,-0.299,-0.125,-0.181,0.609,0.967,-0.142,0.102,-1.0,-0.993,-0.993,-1.0,-0.993,-0.993,0.892,-0.164,0.0946,0.987,-0.115,0.103,-0.402,0.909,-0.97,-0.982,-1.0,-0.992,-0.993,-1.0,-1.0,-0.927,0.00223,0.0275,-0.0567,0.0855,-0.329,0.271,-0.254,0.258,-0.705,0.714,-0.723,0.729,-0.181,0.338,0.643,0.0736,0.0031,-0.00905,-0.991,-0.981,-0.99,-0.991,-0.979,-0.987,-0.987,-0.979,-0.992,0.988,0.992,0.989,-0.988,-1.0,-1.0,-1.0,-0.988,-0.98,-0.982,-0.754,-0.673,-0.747,0.265,0.188,0.465,0.372,0.0827,-0.00462,0.327,0.438,0.258,0.07,0.187,0.247,-0.12,-0.11,-0.04,-0.0317,-0.102,0.0961,-0.976,-0.994,-0.986,-0.975,-0.994,-0.986,-0.865,-0.959,-0.743,0.834,0.906,0.829,-0.976,-1.0,-1.0,-1.0,-0.972,-0.995,-0.987,-0.261,-1.0,-0.248,-0.437,0.239,0.145,-0.114,0.0323,-0.128,0.115,0.125,0.112,-0.166,0.135,0.184,-0.0101,0.0433,-0.351,-0.108,-0.0424,-0.0558,-0.988,-0.996,-0.992,-0.988,-0.996,-0.992,-0.993,-0.994,-0.989,0.989,0.997,0.994,-0.993,-1.0,-1.0,-1.0,-0.987,-0.995,-0.993,-0.544,-0.673,-0.588,-0.241,-0.0114,0.116,0.0896,0.096,0.0096,0.0951,0.253,0.182,-0.169,0.132,0.0082,0.193,0.0737,-0.315,-0.984,-0.988,-0.988,-0.986,-0.995,-0.984,-1.0,-0.986,-0.6,0.038,-0.0742,0.254,-0.296,-0.984,-0.988,-0.988,-0.986,-0.995,-0.984,-1.0,-0.986,-0.6,0.038,-0.0742,0.254,-0.296,-0.989,-0.99,-0.991,-0.989,-0.993,-0.989,-1.0,-0.99,-0.795,0.65,-0.26,-0.128,-0.521,-0.976,-0.986,-0.984,-0.985,-0.966,-0.976,-1.0,-0.983,-0.223,-0.227,0.0597,0.0615,0.0417,-0.993,-0.995,-0.995,-0.995,-0.998,-0.993,-1.0,-0.994,-0.663,0.328,-0.155,-0.221,-0.108,-0.994,-0.973,-0.983,-0.996,-0.966,-0.977,-0.994,-0.972,-0.982,-0.998,-0.963,-0.969,-0.997,-0.99,-0.991,-0.986,-1.0,-0.999,-0.999,-0.989,-0.977,-0.981,-1.0,-0.816,-0.814,-0.935,-1.0,-1.0,0.125,-0.0646,0.0827,-0.727,-0.965,0.163,-0.0922,-0.0449,-0.288,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-0.999,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-0.999,-1.0,-1.0,-1.0,-0.999,-1.0,-0.999,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-0.999,-1.0,-1.0,-1.0,-0.999,-1.0,-0.991,-0.982,-0.988,-0.991,-0.981,-0.99,-0.988,-0.981,-0.988,-0.995,-0.985,-0.994,-0.997,-0.999,-0.998,-0.987,-1.0,-1.0,-1.0,-0.982,-0.985,-0.982,-1.0,-1.0,-1.0,-0.16,-0.48,-0.28,0.115,-0.193,0.0383,-0.595,-0.924,-0.529,-0.913,-0.803,-0.98,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-0.999,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-0.975,-0.994,-0.987,-0.977,-0.993,-0.987,-0.976,-0.994,-0.985,-0.973,-0.995,-0.991,-0.988,-0.997,-0.994,-0.986,-1.0,-1.0,-1.0,-0.986,-0.995,-0.993,-0.591,-0.808,-0.751,-1.0,-0.871,-1.0,-0.217,-0.0173,-0.111,0.0905,-0.245,-0.429,-0.813,-0.392,-0.767,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-0.988,-0.989,-0.986,-0.993,-0.99,-0.988,-1.0,-0.989,-0.907,-0.862,0.258,-0.619,-0.88,-0.989,-0.991,-0.987,-0.993,-1.0,-0.989,-1.0,-0.987,-1.0,-0.905,0.661,-0.725,-0.929,-0.989,-0.986,-0.984,-0.991,-0.996,-0.989,-1.0,-0.993,-0.737,-0.795,-0.213,-0.535,-0.872,-0.995,-0.995,-0.995,-0.996,-0.996,-0.995,-1.0,-0.994,-1.0,-0.556,0.415,-0.391,-0.76,-0.119,0.178,0.101,0.809,-0.849,0.181,-0.0491,5\n0.279,-0.0262,-0.123,-0.996,-0.983,-0.991,-0.997,-0.983,-0.989,-0.939,-0.576,-0.83,0.844,0.682,0.838,-0.986,-1.0,-1.0,-1.0,-0.997,-0.984,-0.986,-0.627,-0.851,-0.912,0.0614,0.0748,0.198,-0.264,0.0725,-0.155,0.323,-0.171,0.295,-0.306,0.482,-0.47,-0.306,-0.363,0.507,0.968,-0.144,0.0999,-0.997,-0.981,-0.978,-0.996,-0.981,-0.978,0.894,-0.164,0.0934,0.987,-0.121,0.0958,-0.4,0.911,-0.969,-0.982,-0.996,-0.981,-0.98,-1.0,-1.0,-0.596,-0.0649,0.0754,-0.0858,0.0962,-0.295,0.228,-0.206,0.205,-0.385,0.386,-0.387,0.385,-0.991,-0.969,0.984,0.0773,0.0201,-0.00986,-0.993,-0.988,-0.993,-0.994,-0.986,-0.991,-0.987,-0.992,-0.99,0.988,0.993,0.993,-0.993,-1.0,-1.0,-1.0,-0.995,-0.987,-0.989,-0.821,-0.755,-0.825,0.123,0.276,0.457,0.193,0.102,-0.0991,0.195,0.484,0.358,-0.187,0.298,0.452,-0.127,-0.0833,0.457,-0.0434,-0.0914,0.0855,-0.991,-0.992,-0.988,-0.992,-0.993,-0.99,-0.885,-0.957,-0.743,0.834,0.906,0.827,-0.982,-1.0,-1.0,-1.0,-0.991,-0.994,-0.995,-0.931,-0.827,-0.543,-0.166,-0.0129,0.32,-0.165,0.0446,-0.125,0.0783,0.177,0.193,-0.207,0.112,0.202,0.21,0.141,-0.725,-0.0912,-0.0363,-0.0605,-0.991,-0.997,-0.993,-0.991,-0.997,-0.994,-0.994,-0.994,-0.989,0.989,0.998,0.994,-0.995,-1.0,-1.0,-1.0,-0.991,-0.997,-0.995,-0.562,-0.731,-0.661,0.00989,-0.138,0.126,0.316,0.0943,0.0262,0.0697,0.247,0.257,-0.137,0.0873,0.149,0.197,0.14,-0.306,-0.987,-0.986,-0.986,-0.986,-0.997,-0.987,-1.0,-0.984,-0.589,-0.0929,0.0464,-0.00047,0.0371,-0.987,-0.986,-0.986,-0.986,-0.997,-0.987,-1.0,-0.984,-0.589,-0.0929,0.0464,-0.00047,0.0371,-0.993,-0.993,-0.993,-0.993,-0.993,-0.993,-1.0,-0.992,-0.792,0.662,-0.247,-0.23,-0.436,-0.982,-0.987,-0.986,-0.99,-0.982,-0.982,-1.0,-0.984,-0.241,-0.202,0.0547,0.11,-0.0794,-0.996,-0.995,-0.995,-0.995,-0.998,-0.996,-1.0,-0.995,-0.683,0.595,-0.265,-0.316,-0.164,-0.995,-0.984,-0.991,-0.996,-0.983,-0.99,-0.995,-0.983,-0.989,-0.997,-0.987,-0.988,-0.994,-0.99,-0.997,-0.993,-1.0,-1.0,-1.0,-0.99,-0.992,-0.988,-1.0,-0.87,-0.944,-1.0,-1.0,-1.0,0.029,0.0803,0.186,-0.599,-0.908,-0.461,-0.813,-0.567,-0.771,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-0.994,-0.989,-0.991,-0.991,-0.987,-0.994,-0.989,-0.987,-0.994,-0.993,-0.988,-0.994,-0.998,-1.0,-0.965,-0.993,-1.0,-1.0,-1.0,-0.992,-0.991,-0.993,-1.0,-1.0,-1.0,-0.12,-0.56,-0.28,0.0358,-0.093,0.168,-0.264,-0.757,-0.396,-0.83,-0.577,-0.893,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-0.999,-1.0,-1.0,-1.0,-1.0,-0.999,-1.0,-1.0,-0.987,-0.994,-0.987,-0.993,-0.992,-0.989,-0.99,-0.993,-0.987,-0.995,-0.992,-0.992,-0.99,-0.994,-0.993,-0.99,-1.0,-1.0,-1.0,-0.993,-0.996,-0.99,-0.724,-0.804,-0.817,-1.0,-1.0,-0.793,0.217,-0.135,-0.0497,-0.572,-0.874,-0.135,-0.542,-0.379,-0.757,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-0.988,-0.987,-0.984,-0.99,-0.998,-0.988,-1.0,-0.983,-0.907,-1.0,0.0736,-0.468,-0.756,-0.993,-0.992,-0.989,-0.994,-0.996,-0.993,-1.0,-0.988,-1.0,1.0,0.679,-0.701,-0.91,-0.989,-0.988,-0.987,-0.987,-0.996,-0.989,-1.0,-0.989,-0.721,-1.0,-0.0357,-0.23,-0.511,-0.995,-0.995,-0.996,-0.995,-0.996,-0.995,-1.0,-0.995,-0.956,-0.937,0.405,-0.117,-0.483,-0.0368,-0.0129,0.64,-0.485,-0.849,0.182,-0.0477,5\n0.277,-0.0166,-0.115,-0.998,-0.981,-0.99,-0.998,-0.98,-0.99,-0.942,-0.569,-0.825,0.849,0.683,0.838,-0.993,-1.0,-1.0,-1.0,-0.998,-0.981,-0.991,-0.787,-0.559,-0.761,0.313,-0.131,0.191,0.0869,0.258,-0.273,0.435,-0.315,0.44,-0.269,0.179,-0.089,-0.156,-0.19,0.599,0.968,-0.149,0.0945,-0.998,-0.988,-0.979,-0.998,-0.989,-0.979,0.894,-0.167,0.0917,0.987,-0.122,0.0941,-0.4,0.912,-0.967,-0.984,-0.998,-0.991,-0.98,-1.0,-1.0,-0.617,-0.257,0.269,-0.281,0.293,-0.167,0.0899,-0.0663,0.0671,-0.237,0.239,-0.241,0.241,-0.408,-0.185,0.965,0.0734,0.0191,0.0168,-0.996,-0.988,-0.992,-0.997,-0.987,-0.991,-0.997,-0.992,-0.99,0.994,0.993,0.986,-0.994,-1.0,-1.0,-1.0,-0.996,-0.987,-0.991,-0.851,-0.746,-0.797,0.241,0.135,0.297,0.287,0.319,-0.143,0.477,0.418,0.39,-0.0303,0.163,0.18,-0.273,0.103,0.0647,-0.034,-0.0747,0.0774,-0.985,-0.992,-0.987,-0.987,-0.993,-0.988,-0.87,-0.953,-0.75,0.839,0.911,0.821,-0.985,-1.0,-1.0,-1.0,-0.99,-0.993,-0.991,-0.629,-0.468,-0.651,-0.213,0.00211,0.388,-0.233,-0.163,0.186,-0.435,0.65,0.24,-0.34,0.133,0.473,-0.142,0.484,-0.725,-0.0908,-0.0376,-0.0583,-0.991,-0.996,-0.995,-0.993,-0.997,-0.994,-0.98,-0.998,-0.993,0.994,0.997,0.997,-0.996,-1.0,-1.0,-1.0,-0.995,-0.997,-0.994,-0.618,-0.683,-0.633,-0.0257,-0.188,0.231,0.2,-0.149,0.272,-0.272,-0.00994,0.235,-0.341,-0.0857,0.164,0.121,0.107,-0.283,-0.993,-0.991,-0.991,-0.991,-0.997,-0.993,-1.0,-0.99,-0.705,0.18,-0.278,0.516,-0.356,-0.993,-0.991,-0.991,-0.991,-0.997,-0.993,-1.0,-0.99,-0.705,0.18,-0.278,0.516,-0.356,-0.993,-0.996,-0.996,-0.993,-0.981,-0.993,-1.0,-0.997,-0.85,0.312,-0.17,0.134,-0.458,-0.985,-0.989,-0.99,-0.987,-0.982,-0.985,-1.0,-0.992,-0.339,-0.237,0.0938,0.0233,0.039,-0.996,-0.995,-0.996,-0.992,-0.992,-0.996,-1.0,-0.996,-0.72,0.332,-0.261,-0.146,-0.00737,-0.997,-0.982,-0.988,-0.999,-0.98,-0.992,-0.998,-0.982,-0.991,-0.999,-0.981,-0.989,-0.995,-0.992,-0.974,-0.992,-1.0,-1.0,-1.0,-0.994,-0.988,-0.986,-1.0,-0.87,-0.944,0.0968,-1.0,-1.0,0.181,0.058,0.56,-0.677,-0.951,-0.18,-0.534,-0.586,-0.79,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-0.999,-0.999,-1.0,-1.0,-1.0,-0.999,-1.0,-1.0,-0.996,-0.989,-0.991,-0.997,-0.989,-0.993,-0.996,-0.989,-0.992,-0.997,-0.99,-0.995,-0.996,-0.996,-0.996,-0.993,-1.0,-1.0,-1.0,-0.996,-0.992,-0.986,-1.0,-1.0,-1.0,-0.32,-0.08,0.04,0.273,0.0791,0.292,-0.522,-0.813,-0.497,-0.904,-0.764,-0.966,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-0.999,-1.0,-1.0,-1.0,-1.0,-0.999,-1.0,-1.0,-0.982,-0.993,-0.989,-0.986,-0.992,-0.988,-0.983,-0.993,-0.986,-0.988,-0.993,-0.991,-0.994,-0.994,-0.995,-0.989,-1.0,-1.0,-1.0,-0.99,-0.996,-0.997,-0.653,-0.827,-0.737,-1.0,-0.806,-1.0,-0.153,-0.0884,-0.162,-0.34,-0.723,-0.265,-0.69,-0.268,-0.659,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-0.994,-0.99,-0.992,-0.991,-0.988,-0.994,-1.0,-0.997,-0.907,-1.0,0.394,-0.113,-0.482,-0.996,-0.994,-0.993,-0.995,-0.982,-0.996,-1.0,-0.994,-1.0,-1.0,0.559,-0.529,-0.859,-0.991,-0.989,-0.988,-0.991,-0.998,-0.991,-1.0,-0.989,-0.763,-0.897,-0.274,-0.51,-0.831,-0.995,-0.995,-0.995,-0.996,-0.997,-0.995,-1.0,-0.995,-1.0,-0.937,0.0878,-0.351,-0.699,0.123,0.123,0.694,-0.616,-0.848,0.185,-0.0439,5\n0.277,-0.0101,-0.105,-0.997,-0.99,-0.995,-0.998,-0.99,-0.996,-0.942,-0.566,-0.823,0.849,0.696,0.846,-0.994,-1.0,-1.0,-1.0,-0.998,-0.992,-0.995,-0.752,-0.455,-0.551,0.39,-0.182,0.159,0.187,0.26,-0.243,0.422,-0.418,0.558,-0.218,0.165,0.0809,-0.21,-0.151,0.18,0.968,-0.148,0.0919,-0.999,-0.987,-0.997,-0.999,-0.987,-0.997,0.894,-0.167,0.0833,0.988,-0.122,0.0941,-0.409,0.912,-0.967,-0.985,-0.999,-0.987,-0.998,-1.0,-1.0,-1.0,-0.302,0.379,-0.457,0.537,-0.198,0.127,-0.108,0.111,-0.158,0.175,-0.193,0.208,-0.564,0.466,0.443,0.0779,0.0187,0.00934,-0.995,-0.989,-0.992,-0.995,-0.987,-0.991,-0.994,-0.992,-0.993,0.994,0.993,0.986,-0.993,-1.0,-1.0,-1.0,-0.995,-0.987,-0.99,-0.779,-0.755,-0.791,0.281,0.1,0.26,0.202,0.351,-0.0773,0.563,0.352,0.369,0.0434,0.147,0.299,-0.375,0.0418,-0.112,-0.0288,-0.0704,0.079,-0.985,-0.992,-0.983,-0.986,-0.992,-0.983,-0.87,-0.953,-0.746,0.84,0.911,0.819,-0.985,-1.0,-1.0,-1.0,-0.985,-0.993,-0.984,-0.364,-0.371,-0.462,-0.403,0.242,0.0591,0.0303,-0.12,0.151,-0.381,0.573,0.104,-0.228,0.138,0.346,-0.448,0.645,-0.746,-0.0942,-0.0434,-0.0419,-0.992,-0.996,-0.993,-0.993,-0.996,-0.993,-0.98,-0.998,-0.993,0.994,0.997,0.997,-0.995,-1.0,-1.0,-1.0,-0.994,-0.996,-0.992,-0.628,-0.681,-0.542,-0.265,0.0558,-0.0456,0.236,-0.122,0.268,-0.194,-0.00532,0.203,-0.297,0.0699,-0.0123,0.0179,0.187,-0.321,-0.994,-0.995,-0.995,-0.996,-0.994,-0.994,-1.0,-0.993,-0.785,0.37,-0.393,0.563,-0.482,-0.994,-0.995,-0.995,-0.996,-0.994,-0.994,-1.0,-0.993,-0.785,0.37,-0.393,0.563,-0.482,-0.993,-0.995,-0.996,-0.993,-0.993,-0.993,-1.0,-0.995,-0.871,0.0727,0.0178,-0.0686,-0.166,-0.986,-0.986,-0.986,-0.987,-0.99,-0.986,-1.0,-0.989,-0.245,-0.173,-0.0078,0.0959,0.0698,-0.995,-0.995,-0.996,-0.992,-0.993,-0.995,-1.0,-0.996,-0.751,0.179,-0.181,0.0496,-0.169,-0.997,-0.987,-0.993,-0.998,-0.992,-0.997,-0.997,-0.99,-0.995,-0.999,-0.993,-0.998,-0.996,-0.995,-0.986,-0.995,-1.0,-1.0,-1.0,-0.995,-0.987,-0.988,-1.0,-0.945,-1.0,-0.613,-1.0,-1.0,0.157,0.319,0.606,-0.631,-0.935,-0.661,-0.899,-0.881,-0.964,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-0.999,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-0.995,-0.988,-0.99,-0.995,-0.99,-0.993,-0.993,-0.99,-0.992,-0.997,-0.993,-0.994,-0.996,-0.999,-0.985,-0.992,-1.0,-1.0,-1.0,-0.991,-0.991,-0.988,-1.0,-1.0,-1.0,-0.32,-0.36,0.52,0.329,0.0548,0.321,-0.595,-0.905,-0.665,-0.956,-0.723,-0.943,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-0.999,-1.0,-1.0,-1.0,-1.0,-0.999,-1.0,-1.0,-0.985,-0.993,-0.981,-0.985,-0.992,-0.985,-0.983,-0.993,-0.984,-0.983,-0.993,-0.988,-0.999,-0.998,-0.982,-0.988,-1.0,-1.0,-1.0,-0.988,-0.994,-0.99,-0.678,-0.808,-0.751,-0.933,-0.935,-0.931,-0.363,-0.133,0.195,-0.00403,-0.323,-0.29,-0.705,-0.235,-0.608,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-0.995,-0.995,-0.994,-0.995,-0.989,-0.995,-1.0,-0.992,-1.0,-1.0,0.438,-0.595,-0.809,-0.995,-0.995,-0.994,-0.994,-0.983,-0.995,-1.0,-0.997,-1.0,-1.0,0.247,-0.521,-0.803,-0.991,-0.986,-0.986,-0.988,-0.995,-0.991,-1.0,-0.992,-0.769,-1.0,-0.297,-0.346,-0.727,-0.995,-0.995,-0.994,-0.996,-0.999,-0.995,-1.0,-0.995,-1.0,-1.0,0.02,-0.545,-0.845,0.0826,-0.143,0.275,-0.368,-0.85,0.185,-0.0421,5\n0.279,-0.0196,-0.11,-0.997,-0.967,-0.983,-0.997,-0.966,-0.983,-0.941,-0.566,-0.817,0.851,0.674,0.834,-0.987,-1.0,-1.0,-1.0,-0.997,-0.972,-0.983,-0.637,-0.515,-0.537,0.36,-0.233,0.226,0.0695,0.0643,-0.0764,0.138,-0.0368,0.231,-0.115,0.319,-0.488,-0.0959,-0.136,0.611,0.968,-0.144,0.0931,-0.999,-0.989,-0.992,-0.999,-0.989,-0.992,0.893,-0.166,0.0852,0.988,-0.12,0.0941,-0.417,0.911,-0.969,-0.985,-0.999,-0.99,-0.991,-1.0,-1.0,-1.0,-0.301,0.401,-0.503,0.606,-0.423,0.374,-0.362,0.367,-0.128,0.138,-0.147,0.153,0.726,0.939,0.879,0.0822,-0.017,-0.0158,-0.995,-0.985,-0.988,-0.996,-0.983,-0.989,-0.994,-0.988,-0.982,0.994,0.991,0.989,-0.992,-1.0,-1.0,-1.0,-0.996,-0.98,-0.99,-0.788,-0.726,-0.749,0.318,0.0311,0.308,0.24,0.0785,-0.00397,0.171,0.18,0.293,0.155,0.244,0.612,0.108,0.255,0.265,-0.0286,-0.083,0.0955,-0.988,-0.989,-0.979,-0.988,-0.99,-0.98,-0.881,-0.954,-0.743,0.839,0.907,0.819,-0.984,-1.0,-1.0,-1.0,-0.987,-0.992,-0.982,-0.374,-0.57,-0.166,-0.0949,-0.0377,0.335,-0.101,-0.0469,-0.0549,0.0634,0.24,0.0176,-0.117,0.0488,0.336,-0.0161,0.466,-0.688,-0.0971,-0.0416,-0.0447,-0.99,-0.995,-0.99,-0.99,-0.996,-0.99,-0.991,-0.996,-0.992,0.992,0.997,0.995,-0.994,-1.0,-1.0,-1.0,-0.99,-0.996,-0.989,-0.52,-0.666,-0.5,0.00959,-0.131,0.108,0.417,-0.0525,0.0512,-0.0398,0.369,0.0208,-0.112,-0.111,0.213,0.218,0.204,-0.416,-0.987,-0.983,-0.987,-0.978,-0.993,-0.987,-1.0,-0.991,-0.586,0.156,-0.24,0.293,-0.0627,-0.987,-0.983,-0.987,-0.978,-0.993,-0.987,-1.0,-0.991,-0.586,0.156,-0.24,0.293,-0.0627,-0.991,-0.989,-0.991,-0.986,-0.993,-0.991,-1.0,-0.993,-0.795,0.178,0.0616,-0.187,-0.207,-0.986,-0.985,-0.982,-0.988,-0.993,-0.986,-1.0,-0.98,-0.219,-0.0993,-0.0913,0.196,-0.0113,-0.994,-0.995,-0.995,-0.996,-0.993,-0.994,-1.0,-0.994,-0.681,0.265,-0.255,0.203,-0.365,-0.996,-0.968,-0.984,-0.997,-0.968,-0.983,-0.998,-0.972,-0.983,-0.997,-0.969,-0.977,-0.995,-0.996,-0.996,-0.986,-1.0,-0.999,-1.0,-0.997,-0.981,-0.978,-1.0,-0.758,-0.869,-0.484,-1.0,-1.0,0.432,0.11,0.38,-0.321,-0.708,-0.0994,-0.428,-0.263,-0.506,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-0.999,-1.0,-1.0,-0.999,-1.0,-0.999,-0.999,-0.999,-0.999,-1.0,-0.999,-0.999,-0.999,-0.999,-1.0,-1.0,-0.999,-1.0,-1.0,-1.0,-0.999,-0.999,-1.0,-1.0,-1.0,-0.999,-1.0,-1.0,-0.995,-0.983,-0.987,-0.996,-0.988,-0.988,-0.995,-0.988,-0.988,-0.995,-0.991,-0.989,-0.985,-0.993,-0.967,-0.989,-1.0,-1.0,-1.0,-0.995,-0.99,-0.987,-1.0,-1.0,-1.0,-0.12,-0.6,0.0,0.356,0.0508,0.209,-0.298,-0.652,-0.643,-0.95,-0.42,-0.833,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-0.999,-1.0,-1.0,-1.0,-1.0,-0.999,-1.0,-1.0,-0.986,-0.99,-0.978,-0.989,-0.988,-0.981,-0.985,-0.99,-0.978,-0.99,-0.992,-0.987,-1.0,-0.994,-0.993,-0.986,-1.0,-1.0,-1.0,-0.986,-0.993,-0.987,-0.661,-0.716,-0.709,-1.0,-0.935,-1.0,-0.307,-0.346,-0.0792,-0.406,-0.755,-0.3,-0.729,-0.369,-0.75,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-0.982,-0.985,-0.982,-0.989,-0.975,-0.982,-1.0,-0.99,-0.844,-1.0,0.22,-0.473,-0.784,-0.988,-0.991,-0.988,-0.994,-0.976,-0.988,-1.0,-0.991,-1.0,-0.905,0.29,-0.669,-0.933,-0.988,-0.985,-0.984,-0.985,-0.995,-0.988,-1.0,-0.989,-0.736,-1.0,-0.257,-0.322,-0.658,-0.996,-0.995,-0.994,-0.994,-0.997,-0.996,-1.0,-0.994,-0.956,-1.0,0.146,-0.217,-0.564,-0.213,-0.231,0.0146,-0.19,-0.852,0.182,-0.043,5\n0.277,-0.0305,-0.125,-0.997,-0.967,-0.982,-0.996,-0.966,-0.983,-0.941,-0.573,-0.817,0.85,0.67,0.832,-0.977,-1.0,-0.999,-0.999,-0.996,-0.976,-0.987,-0.633,-0.744,-0.822,0.363,-0.301,0.347,-0.0637,0.144,-0.132,0.0832,0.0416,0.137,-0.0923,0.372,-0.721,-0.162,-0.0171,0.561,0.968,-0.147,0.0917,-0.998,-0.973,-0.977,-0.998,-0.973,-0.977,0.894,-0.166,0.0852,0.988,-0.129,0.0859,-0.413,0.913,-0.968,-0.985,-0.998,-0.976,-0.982,-1.0,-1.0,-0.59,-0.368,0.39,-0.412,0.433,-0.471,0.421,-0.405,0.405,-0.143,0.139,-0.135,0.13,-0.933,-0.859,0.982,0.0724,0.00875,-0.00447,-0.995,-0.981,-0.99,-0.995,-0.978,-0.992,-0.996,-0.988,-0.982,0.994,0.991,0.989,-0.991,-1.0,-1.0,-1.0,-0.993,-0.977,-0.995,-0.807,-0.672,-0.778,0.388,-0.0173,0.387,0.394,0.163,0.0258,0.123,0.274,0.291,0.169,0.332,0.53,0.21,0.304,0.192,-0.0242,-0.0779,0.0941,-0.989,-0.987,-0.979,-0.989,-0.988,-0.976,-0.879,-0.953,-0.743,0.839,0.907,0.826,-0.983,-1.0,-1.0,-1.0,-0.989,-0.99,-0.975,-0.255,-0.403,-0.243,-0.0523,-0.11,0.446,-0.183,-0.0859,-0.0132,-0.0539,0.366,0.166,-0.283,0.177,0.308,0.204,0.193,-0.733,-0.103,-0.0355,-0.0632,-0.991,-0.996,-0.991,-0.991,-0.996,-0.99,-0.991,-0.996,-0.992,0.992,0.997,0.995,-0.994,-1.0,-1.0,-1.0,-0.991,-0.996,-0.989,-0.582,-0.668,-0.565,0.076,-0.224,0.238,0.335,-0.087,0.0739,-0.138,0.321,0.206,-0.304,0.00519,0.101,0.264,0.208,-0.385,-0.977,-0.976,-0.977,-0.978,-0.988,-0.977,-0.999,-0.975,-0.448,0.0497,-0.14,0.15,0.0351,-0.977,-0.976,-0.977,-0.978,-0.988,-0.977,-0.999,-0.975,-0.448,0.0497,-0.14,0.15,0.0351,-0.991,-0.99,-0.992,-0.986,-0.976,-0.991,-1.0,-0.992,-0.831,0.261,0.0351,-0.17,-0.343,-0.985,-0.987,-0.986,-0.988,-0.993,-0.985,-1.0,-0.987,-0.257,-0.0536,-0.127,0.227,-0.0644,-0.994,-0.995,-0.995,-0.996,-0.992,-0.994,-1.0,-0.994,-0.646,0.327,-0.329,0.234,-0.352,-0.995,-0.974,-0.989,-0.997,-0.964,-0.978,-0.996,-0.973,-0.985,-0.998,-0.962,-0.967,-0.992,-0.999,-0.994,-0.989,-1.0,-0.999,-1.0,-0.991,-0.985,-0.986,-1.0,-0.816,-0.889,-1.0,-1.0,-1.0,0.00077,-0.123,0.157,-0.664,-0.942,0.167,-0.118,0.23,0.0557,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-0.999,-1.0,-1.0,-1.0,-0.999,-0.999,-1.0,-1.0,-0.999,-1.0,-0.999,-1.0,-0.999,-1.0,-0.999,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-0.995,-0.981,-0.991,-0.996,-0.983,-0.988,-0.995,-0.982,-0.989,-0.997,-0.988,-0.988,-0.994,-0.991,-0.994,-0.99,-1.0,-1.0,-1.0,-0.992,-0.984,-0.99,-1.0,-1.0,-1.0,-0.2,-0.48,-0.04,0.295,0.0229,0.0269,-0.606,-0.871,-0.636,-0.953,-0.38,-0.772,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-0.999,-0.999,-1.0,-1.0,-1.0,-1.0,-0.999,-1.0,-1.0,-0.999,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-0.987,-0.99,-0.98,-0.99,-0.986,-0.98,-0.988,-0.99,-0.979,-0.99,-0.986,-0.982,-0.996,-0.995,-0.993,-0.987,-1.0,-1.0,-1.0,-0.991,-0.995,-0.993,-0.707,-0.74,-0.733,-0.867,-1.0,-1.0,-0.0881,-0.208,-0.076,-0.181,-0.55,0.0452,-0.353,-0.0607,-0.411,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-0.982,-0.975,-0.977,-0.975,-0.998,-0.982,-0.999,-0.987,-0.854,-1.0,-0.11,0.0805,-0.184,-0.99,-0.99,-0.987,-0.994,-0.98,-0.99,-1.0,-0.99,-1.0,-0.968,0.25,-0.656,-0.933,-0.989,-0.987,-0.986,-0.988,-0.998,-0.989,-1.0,-0.99,-0.736,-1.0,-0.197,-0.407,-0.733,-0.996,-0.995,-0.995,-0.994,-0.997,-0.996,-1.0,-0.995,-0.956,-1.0,0.136,-0.0823,-0.422,-0.0209,0.594,-0.562,0.467,-0.851,0.184,-0.042,5\n0.277,-0.0218,-0.121,-0.997,-0.961,-0.984,-0.998,-0.957,-0.984,-0.941,-0.564,-0.824,0.85,0.67,0.832,-0.983,-1.0,-1.0,-0.999,-0.997,-0.957,-0.986,-0.683,-0.525,-0.759,0.358,-0.253,0.267,-0.124,0.215,-0.183,0.172,-0.069,0.242,-0.194,0.217,-0.338,-0.165,-0.0338,0.724,0.968,-0.154,0.0851,-0.998,-0.976,-0.969,-0.998,-0.976,-0.969,0.894,-0.168,0.0845,0.988,-0.13,0.0832,-0.41,0.913,-0.964,-0.987,-0.997,-0.979,-0.969,-1.0,-1.0,-0.456,-0.288,0.292,-0.295,0.299,-0.329,0.263,-0.24,0.236,-0.505,0.504,-0.502,0.497,0.344,0.553,0.968,0.0753,0.0308,0.0112,-0.996,-0.98,-0.997,-0.996,-0.978,-0.997,-0.996,-0.988,-0.991,0.997,0.979,0.989,-0.993,-1.0,-1.0,-1.0,-0.994,-0.977,-0.998,-0.875,-0.661,-0.868,0.376,0.0772,0.378,0.326,0.222,0.059,0.177,0.483,0.279,-0.0188,0.201,0.171,-0.301,-0.0606,0.0644,-0.0248,-0.0664,0.0779,-0.991,-0.993,-0.987,-0.991,-0.994,-0.988,-0.879,-0.953,-0.749,0.842,0.908,0.822,-0.988,-1.0,-1.0,-1.0,-0.99,-0.995,-0.989,-0.323,-0.314,-0.591,-0.0909,-0.0383,0.41,-0.284,-0.171,0.0402,0.229,-0.0273,0.181,-0.283,0.342,-0.0592,-0.187,0.234,-0.442,-0.101,-0.0477,-0.0677,-0.992,-0.996,-0.994,-0.993,-0.997,-0.994,-0.99,-0.997,-0.996,0.992,0.994,0.996,-0.996,-1.0,-1.0,-1.0,-0.993,-0.997,-0.993,-0.635,-0.765,-0.688,0.0866,-0.11,0.243,0.461,-0.134,-0.0135,0.199,-0.0371,0.295,-0.266,0.24,0.187,0.285,-0.141,-0.258,-0.984,-0.978,-0.979,-0.978,-0.994,-0.984,-1.0,-0.98,-0.495,0.383,-0.337,0.219,-0.162,-0.984,-0.978,-0.979,-0.978,-0.994,-0.984,-1.0,-0.98,-0.495,0.383,-0.337,0.219,-0.162,-0.993,-0.993,-0.994,-0.99,-0.985,-0.993,-1.0,-0.997,-0.851,0.161,-0.315,0.0355,0.161,-0.989,-0.991,-0.99,-0.991,-0.992,-0.989,-1.0,-0.99,-0.377,-0.0937,0.0628,-0.111,0.116,-0.996,-0.996,-0.996,-0.996,-0.992,-0.996,-1.0,-0.996,-0.687,0.48,-0.259,-0.00745,-0.367,-0.997,-0.968,-0.991,-0.997,-0.959,-0.98,-0.997,-0.97,-0.988,-0.997,-0.954,-0.968,-0.998,-0.974,-0.986,-0.989,-1.0,-0.999,-1.0,-0.995,-0.979,-0.99,-1.0,-0.85,-0.889,-1.0,-1.0,-1.0,-0.028,0.154,0.165,-0.36,-0.726,0.414,0.228,0.334,0.162,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-0.999,-1.0,-1.0,-0.999,-0.999,-0.999,-0.999,-1.0,-0.999,-1.0,-0.999,-0.999,-0.999,-0.999,-0.999,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-0.997,-0.98,-0.996,-0.997,-0.981,-0.995,-0.995,-0.981,-0.996,-0.997,-0.985,-0.991,-1.0,-0.983,-0.982,-0.993,-1.0,-1.0,-1.0,-0.996,-0.984,-0.993,-1.0,-1.0,-1.0,-0.2,0.2,-0.04,0.286,0.152,0.25,-0.477,-0.799,-0.49,-0.913,-0.279,-0.632,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-0.999,-1.0,-0.999,-1.0,-1.0,-1.0,-1.0,-0.999,-1.0,-1.0,-0.999,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-0.989,-0.992,-0.984,-0.991,-0.994,-0.99,-0.989,-0.994,-0.986,-0.992,-0.994,-0.993,-0.999,-0.982,-0.987,-0.99,-1.0,-1.0,-1.0,-0.99,-0.994,-0.991,-0.707,-0.827,-0.731,-1.0,-1.0,-0.793,-0.184,0.177,0.213,-0.346,-0.694,-0.29,-0.667,-0.514,-0.842,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-0.983,-0.977,-0.979,-0.978,-0.984,-0.983,-1.0,-0.989,-0.907,-1.0,0.0838,0.0375,-0.295,-0.992,-0.993,-0.991,-0.995,-0.996,-0.992,-1.0,-0.992,-1.0,-1.0,0.272,-0.75,-0.929,-0.992,-0.992,-0.991,-0.992,-0.995,-0.992,-1.0,-0.991,-0.85,-1.0,0.0734,-0.371,-0.675,-0.995,-0.996,-0.996,-0.995,-0.994,-0.995,-1.0,-0.995,-0.956,-1.0,0.314,-0.269,-0.573,0.013,0.0809,-0.234,0.118,-0.848,0.189,-0.0374,5\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "head phone_activity.csv"
   ]
  },
  {
   "source": [
    "# Measurements"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING: Could not detect a GPU. Neural Network generation will be slow.\n",
      "\n",
      "\u001b[01;1mBrainome Table Compiler 0.991\u001b[0m\n",
      "Copyright (c) 2019-2021 Brainome, Inc. All Rights Reserved.\n",
      "Licensed to:                 Alexander Makhratchev  (Evaluation)\n",
      "Expiration Date:             2021-04-30   44 days left\n",
      "Maximum File Size:           30 GB\n",
      "Maximum Instances:           unlimited\n",
      "Maximum Attributes:          unlimited\n",
      "Maximum Classes:             unlimited\n",
      "Connected to:                daimensions.brainome.ai  (local execution)\n",
      "\n",
      "\u001b[01;1mCommand:\u001b[0m\n",
      "    btc phone_activity.csv -measureonly\n",
      "\n",
      "Start Time:                 03/17/2021, 05:15 UTC\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[01;1mPre-training Measurements\u001b[0m\n",
      "Data:\n",
      "    Input:                      phone_activity.csv\n",
      "    Target Column:              activity\n",
      "    Number of instances:      10299\n",
      "    Number of attributes:       561 out of 561\n",
      "    Number of classes:            6\n",
      "\n",
      "Class Balance:                \n",
      "                               5: 18.51%\n",
      "                               4: 17.25%\n",
      "                               6: 18.88%\n",
      "                               1: 16.72%\n",
      "                               3: 13.65%\n",
      "                               2: 14.99%\n",
      "\n",
      "Learnability:\n",
      "    Best guess accuracy:          18.88%\n",
      "    Data Sufficiency:             Maybe enough data to generalize. [yellow]\n",
      "\n",
      "Capacity Progression:             at [ 5%, 10%, 20%, 40%, 80%, 100% ]\n",
      "    Ideal Machine Learner:             10,  11,  12,  12,  13,  13\n",
      "\n",
      "\n",
      "\n",
      "Expected Generalization:\n",
      "    Decision Tree:                 4.10 bits/bit\n",
      "    Neural Network:               61.08 bits/bit\n",
      "    Random Forest:                96.25 bits/bit\n",
      "\n",
      "Expected Accuracy:              Training            Validation\n",
      "    Decision Tree:               100.00%                37.25%\n",
      "    Neural Network:               99.65%                98.02%\n",
      "    Random Forest:               100.00%                97.92%\n",
      "\n",
      "Recommendations:\n",
      " \n",
      "\n",
      "Time to Build Estimates:\n",
      "    Decision Tree:                less than a minute    Neural Network:                 31 minutes\n",
      "\n",
      "\n",
      "End Time:           03/17/2021, 05:19 UTC\n",
      "Runtime Duration:   3m 51s\n"
     ]
    }
   ],
   "source": [
    "! btc phone_activity.csv -measureonly"
   ]
  },
  {
   "source": [
    "For this dataset, we will use a brute force approach for model selection. The tryall.py script allows us to try all 6 possible model configurations on a single dataset in a single line of code. The 3 models are decision tree, neural networks, and random forests, and we can also run each model with the -rank command."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Error while deleting file :  clean005828786797.csv\n",
      "Error while deleting file :  clean.state\n",
      "Cleaning...\n",
      "./btc 'phone_activity.csv' -cleanonly --yes\n",
      "WARNING: Could not detect a GPU. Neural Network generation will be slow.\n",
      "\n",
      "\u001b[01;1mBrainome Table Compiler 0.991\u001b[0m\n",
      "Copyright (c) 2019-2021 Brainome, Inc. All Rights Reserved.\n",
      "Licensed to:                 Alexander Makhratchev  (Evaluation)\n",
      "Expiration Date:             2021-04-30   44 days left\n",
      "Maximum File Size:           30 GB\n",
      "Maximum Instances:           unlimited\n",
      "Maximum Attributes:          unlimited\n",
      "Maximum Classes:             unlimited\n",
      "Connected to:                daimensions.brainome.ai  (local execution)\n",
      "\n",
      "\u001b[01;1mCommand:\u001b[0m\n",
      "    btc phone_activity.csv -cleanonly --yes\n",
      "\n",
      "Start Time:                 03/17/2021, 05:19 UTC\n",
      "\n",
      "\n",
      "\n",
      "\u001b[01;1mMessages:\u001b[0m\n",
      "    Clean only output: clean.csv, clean.state\n",
      "\n",
      "End Time:           03/17/2021, 05:19 UTC\n",
      "Runtime Duration:   24s\n",
      "Done Cleaning!\n",
      "Splitting Data...\n",
      "Done Splitting Data!\n",
      "##################################################\n",
      "Running: DT -rank\n",
      "./btc 'train.csv' -headerless -f DT -rank -o DTrank.py -riskoverfit --yes\n",
      "WARNING: Could not detect a GPU. Neural Network generation will be slow.\n",
      "\n",
      "\u001b[01;1mBrainome Table Compiler 0.991\u001b[0m\n",
      "Copyright (c) 2019-2021 Brainome, Inc. All Rights Reserved.\n",
      "Licensed to:                 Alexander Makhratchev  (Evaluation)\n",
      "Expiration Date:             2021-04-30   44 days left\n",
      "Maximum File Size:           30 GB\n",
      "Maximum Instances:           unlimited\n",
      "Maximum Attributes:          unlimited\n",
      "Maximum Classes:             unlimited\n",
      "Connected to:                daimensions.brainome.ai  (local execution)\n",
      "\n",
      "\u001b[01;1mCommand:\u001b[0m\n",
      "    btc train.csv -headerless -f DT -rank -o DTrank.py -riskoverfit --yes\n",
      "\n",
      "Start Time:                 03/17/2021, 05:19 UTC\n",
      "\n",
      "Cleaning...\n",
      "\n",
      "\n",
      "\u001b[01;1mAttribute Ranking:\u001b[0m\n",
      "    Columns selected:           53, 366, 310, 388, 422, \n",
      "    Risk of coincidental column correlation:    0.0%\n",
      "    \n",
      "    Test Accuracy Progression:\n",
      "                                 53 :   56.07%\n",
      "                                366 :   61.27% change   +5.20%\n",
      "                                310 :   66.07% change   +4.80%\n",
      "                                388 :   66.28% change   +0.21%\n",
      "                                422 :   66.32% change   +0.04%\n",
      "         \n",
      "\n",
      "\n",
      "\n",
      "\u001b[01;1mPre-training Measurements\u001b[0m\n",
      "Data:\n",
      "    Input:                      train.csv (headerless csv)\n",
      "    Target Column:              target\n",
      "    Number of instances:       5149\n",
      "    Number of attributes:         5 out of 561\n",
      "    Number of classes:            6\n",
      "\n",
      "Class Balance:                \n",
      "                               0: 16.72%\n",
      "                               1: 14.99%\n",
      "                               2: 13.65%\n",
      "                               3: 17.25%\n",
      "                               4: 18.51%\n",
      "                               5: 18.88%\n",
      "\n",
      "Learnability:\n",
      "    Best guess accuracy:          18.88%\n",
      "    Data Sufficiency:             Maybe enough data to generalize. [yellow]\n",
      "\n",
      "Capacity Progression:             at [ 5%, 10%, 20%, 40%, 80%, 100% ]\n",
      "    Ideal Machine Learner:              8,   9,  10,  10,  11,  11\n",
      "\n",
      "\n",
      "\n",
      "Expected Generalization:\n",
      "    Decision Tree:                10.02 bits/bit\n",
      "    Neural Network:              353.00 bits/bit\n",
      "    Random Forest:                13.55 bits/bit\n",
      "\n",
      "Expected Accuracy:              Training            Validation\n",
      "    Decision Tree:                89.26%                66.30%\n",
      "    Neural Network:               82.32%                82.10%\n",
      "    Random Forest:                99.22%                84.47%\n",
      "\n",
      "Recommendations:\n",
      "    Note: Model type DT given by user. \n",
      "\n",
      "Time to Build Estimates:\n",
      "    Decision Tree:                a few seconds\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[01;1mPredictor:\u001b[0m                        DTrank.py\n",
      "    Classifier Type:              Decision Tree\n",
      "    System Type:                  6-way classifier\n",
      "    Training / Validation Split:    Unable to split dataset. The predictor was trained and evaluated on the same data.\n",
      "    Accuracy:\n",
      "      Best-guess accuracy:        18.88%\n",
      "\n",
      "\n",
      "      Combined Model Accuracy:    86.50% (4454/5149 correct)\n",
      "\n",
      "    Model Capacity (MEC):       1182    bits\n",
      "\n",
      "    Generalization Ratio:          9.69 bits/bit\n",
      "    Generalization Index:          3.13\n",
      "    Percent of Data Memorized:    31.99%\n",
      "    Resilience to Noise:          -0.58 dB\n",
      "\n",
      "    Combined Confusion Matrix:\n",
      "              Actual | Predicted\n",
      "                   0 |   764    84    11     0     0     2 \n",
      "                   1 |   222   533    12     0     0     5 \n",
      "                   2 |    68    35   600     0     0     0 \n",
      "                   3 |     0     0     0   821    43    24 \n",
      "                   4 |     0     0     0    67   880     6 \n",
      "                   5 |    17    35     0    40    24   856 \n",
      "\n",
      "\n",
      "\n",
      "    Combined Accuracy by Class:\n",
      "               class |    TP    FP    TN    FN     TPR      TNR      PPV      NPV       F1       TS \n",
      "                   0 |   764   307  3981    97   88.73%   97.62%   71.34%   97.62%   79.09%   65.41%\n",
      "                   1 |   533   154  4223   239   69.04%   94.64%   77.58%   94.64%   73.06%   57.56%\n",
      "                   2 |   600    23  4423   103   85.35%   97.72%   96.31%   97.72%   90.50%   82.64%\n",
      "                   3 |   821   107  4154    67   92.45%   98.41%   88.47%   98.41%   90.42%   82.51%\n",
      "                   4 |   880    67  4129    73   92.34%   98.26%   92.93%   98.26%   92.63%   86.27%\n",
      "                   5 |   856    37  4140   116   88.07%   97.27%   95.86%   97.27%   91.80%   84.84%\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "End Time:           03/17/2021, 05:23 UTC\n",
      "Runtime Duration:   3m 26s\n",
      "Testing on heldout data using  DT -rank achieved 62.17% test accuracy\n",
      "##################################################\n",
      "Running: NN -rank\n",
      "./btc 'train.csv' -headerless -f NN -rank -o NNrank.py -riskoverfit --yes\n",
      "WARNING: Could not detect a GPU. Neural Network generation will be slow.\n",
      "\n",
      "\u001b[01;1mBrainome Table Compiler 0.991\u001b[0m\n",
      "Copyright (c) 2019-2021 Brainome, Inc. All Rights Reserved.\n",
      "Licensed to:                 Alexander Makhratchev  (Evaluation)\n",
      "Expiration Date:             2021-04-30   44 days left\n",
      "Maximum File Size:           30 GB\n",
      "Maximum Instances:           unlimited\n",
      "Maximum Attributes:          unlimited\n",
      "Maximum Classes:             unlimited\n",
      "Connected to:                daimensions.brainome.ai  (local execution)\n",
      "\n",
      "\u001b[01;1mCommand:\u001b[0m\n",
      "    btc train.csv -headerless -f NN -rank -o NNrank.py -riskoverfit --yes\n",
      "\n",
      "Start Time:                 03/17/2021, 05:23 UTC\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[01;1mAttribute Ranking:\u001b[0m\n",
      "    Columns selected:           53, 366, 310, 388, 422, \n",
      "    Risk of coincidental column correlation:    0.0%\n",
      "    \n",
      "    Test Accuracy Progression:\n",
      "                                 53 :   56.07%\n",
      "                                366 :   61.27% change   +5.20%\n",
      "                                310 :   66.07% change   +4.80%\n",
      "                                388 :   66.28% change   +0.21%\n",
      "                                422 :   66.32% change   +0.04%\n",
      "         \n",
      "\n",
      "\n",
      "\n",
      "\u001b[01;1mPre-training Measurements\u001b[0m\n",
      "Data:\n",
      "    Input:                      train.csv (headerless csv)\n",
      "    Target Column:              target\n",
      "    Number of instances:       5149\n",
      "    Number of attributes:         5 out of 561\n",
      "    Number of classes:            6\n",
      "\n",
      "Class Balance:                \n",
      "                               0: 16.72%\n",
      "                               1: 14.99%\n",
      "                               2: 13.65%\n",
      "                               3: 17.25%\n",
      "                               4: 18.51%\n",
      "                               5: 18.88%\n",
      "\n",
      "Learnability:\n",
      "    Best guess accuracy:          18.88%\n",
      "    Data Sufficiency:             Maybe enough data to generalize. [yellow]\n",
      "\n",
      "Capacity Progression:             at [ 5%, 10%, 20%, 40%, 80%, 100% ]\n",
      "    Ideal Machine Learner:              8,   9,  10,  10,  11,  11\n",
      "\n",
      "\n",
      "\n",
      "Expected Generalization:\n",
      "    Decision Tree:                10.02 bits/bit\n",
      "    Neural Network:              353.00 bits/bit\n",
      "    Random Forest:                13.55 bits/bit\n",
      "\n",
      "Expected Accuracy:              Training            Validation\n",
      "    Decision Tree:                89.26%                66.30%\n",
      "    Neural Network:               82.32%                82.10%\n",
      "    Random Forest:                99.22%                84.47%\n",
      "\n",
      "Recommendations:\n",
      "    Note: Model type NN given by user. \n",
      "\n",
      "Time to Build Estimates:\n",
      "    Neural Network:                 21 minutes\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[01;1mPredictor:\u001b[0m                        NNrank.py\n",
      "    Classifier Type:              Neural Network\n",
      "    System Type:                  6-way classifier\n",
      "    Training / Validation Split:    Unable to split dataset. The predictor was trained and evaluated on the same data.\n",
      "    Accuracy:\n",
      "      Best-guess accuracy:        18.88%\n",
      "\n",
      "\n",
      "      Combined Model Accuracy:    85.29% (4392/5149 correct)\n",
      "\n",
      "    Model Capacity (MEC):        132    bits\n",
      "    Model Capacity Utilized:     132    bits \n",
      "    Generalization Ratio:         85.70 bits/bit\n",
      "    Generalization Index:         27.66\n",
      "    Percent of Data Memorized:     3.62%\n",
      "    Resilience to Noise:          -1.52 dB\n",
      "\n",
      "    Combined Confusion Matrix:\n",
      "              Actual | Predicted\n",
      "                   0 |   749    65    47     0     0     0 \n",
      "                   1 |    89   656    27     0     0     0 \n",
      "                   2 |    72    45   586     0     0     0 \n",
      "                   3 |     0     0     0   702    98    88 \n",
      "                   4 |     0     0     0   134   807    12 \n",
      "                   5 |     0     0     0    53    27   892 \n",
      "\n",
      "\n",
      "\n",
      "    Combined Accuracy by Class:\n",
      "               class |    TP    FP    TN    FN     TPR      TNR      PPV      NPV       F1       TS \n",
      "                   0 |   749   161  4127   112   86.99%   97.36%   82.31%   97.36%   84.58%   73.29%\n",
      "                   1 |   656   110  4267   116   84.97%   97.35%   85.64%   97.35%   85.31%   74.38%\n",
      "                   2 |   586    74  4372   117   83.36%   97.39%   88.79%   97.39%   85.99%   75.42%\n",
      "                   3 |   702   187  4074   186   79.05%   95.63%   78.97%   95.63%   79.01%   65.30%\n",
      "                   4 |   807   125  4071   146   84.68%   96.54%   86.59%   96.54%   85.62%   74.86%\n",
      "                   5 |   892   100  4077    80   91.77%   98.08%   89.92%   98.08%   90.84%   83.21%\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "End Time:           03/17/2021, 05:30 UTC\n",
      "Runtime Duration:   7m 37s\n",
      "Testing on heldout data using  NN -rank achieved 83.67% test accuracy\n",
      "##################################################\n",
      "Running: RF -rank\n",
      "./btc 'train.csv' -headerless -f RF -rank -o RFrank.py -riskoverfit --yes\n",
      "WARNING: Could not detect a GPU. Neural Network generation will be slow.\n",
      "\n",
      "\u001b[01;1mBrainome Table Compiler 0.991\u001b[0m\n",
      "Copyright (c) 2019-2021 Brainome, Inc. All Rights Reserved.\n",
      "Licensed to:                 Alexander Makhratchev  (Evaluation)\n",
      "Expiration Date:             2021-04-30   44 days left\n",
      "Maximum File Size:           30 GB\n",
      "Maximum Instances:           unlimited\n",
      "Maximum Attributes:          unlimited\n",
      "Maximum Classes:             unlimited\n",
      "Connected to:                daimensions.brainome.ai  (local execution)\n",
      "\n",
      "\u001b[01;1mCommand:\u001b[0m\n",
      "    btc train.csv -headerless -f RF -rank -o RFrank.py -riskoverfit --yes\n",
      "\n",
      "Start Time:                 03/17/2021, 05:31 UTC\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[01;1mAttribute Ranking:\u001b[0m\n",
      "    Columns selected:           53, 366, 310, 388, 422, \n",
      "    Risk of coincidental column correlation:    0.0%\n",
      "    \n",
      "    Test Accuracy Progression:\n",
      "                                 53 :   56.07%\n",
      "                                366 :   61.27% change   +5.20%\n",
      "                                310 :   66.07% change   +4.80%\n",
      "                                388 :   66.28% change   +0.21%\n",
      "                                422 :   66.32% change   +0.04%\n",
      "         \n",
      "\n",
      "\n",
      "\n",
      "\u001b[01;1mPre-training Measurements\u001b[0m\n",
      "Data:\n",
      "    Input:                      train.csv (headerless csv)\n",
      "    Target Column:              target\n",
      "    Number of instances:       5149\n",
      "    Number of attributes:         5 out of 561\n",
      "    Number of classes:            6\n",
      "\n",
      "Class Balance:                \n",
      "                               0: 16.72%\n",
      "                               1: 14.99%\n",
      "                               2: 13.65%\n",
      "                               3: 17.25%\n",
      "                               4: 18.51%\n",
      "                               5: 18.88%\n",
      "\n",
      "Learnability:\n",
      "    Best guess accuracy:          18.88%\n",
      "    Data Sufficiency:             Maybe enough data to generalize. [yellow]\n",
      "\n",
      "Capacity Progression:             at [ 5%, 10%, 20%, 40%, 80%, 100% ]\n",
      "    Ideal Machine Learner:              8,   9,  10,  10,  11,  11\n",
      "\n",
      "\n",
      "\n",
      "Expected Generalization:\n",
      "    Decision Tree:                10.02 bits/bit\n",
      "    Neural Network:              353.00 bits/bit\n",
      "    Random Forest:                13.55 bits/bit\n",
      "\n",
      "Expected Accuracy:              Training            Validation\n",
      "    Decision Tree:                89.26%                66.30%\n",
      "    Neural Network:               82.32%                82.10%\n",
      "    Random Forest:                99.22%                84.47%\n",
      "\n",
      "Recommendations:\n",
      "    Note: Model type RF given by user. \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[01;1mPredictor:\u001b[0m                        RFrank.py\n",
      "    Classifier Type:              Random Forest\n",
      "    System Type:                  6-way classifier\n",
      "    Training / Validation Split:    Unable to split dataset. The predictor was trained and evaluated on the same data.\n",
      "    Accuracy:\n",
      "      Best-guess accuracy:        18.88%\n",
      "\n",
      "\n",
      "      Combined Model Accuracy:    98.64% (5079/5149 correct)\n",
      "\n",
      "    Model Capacity (MEC):         13    bits\n",
      "\n",
      "    Generalization Ratio:       1006.39 bits/bit\n",
      "    Generalization Index:        324.77\n",
      "    Percent of Data Memorized:     0.31%\n",
      "    Resilience to Noise:          -2.59 dB\n",
      "\n",
      "    Combined Confusion Matrix:\n",
      "              Actual | Predicted\n",
      "                   0 |   861     0     0     0     0     0 \n",
      "                   1 |     0   772     0     0     0     0 \n",
      "                   2 |     0     0   703     0     0     0 \n",
      "                   3 |     0     0     0   850    34     4 \n",
      "                   4 |     0     0     0     9   944     0 \n",
      "                   5 |     0     0     0    17     6   949 \n",
      "\n",
      "\n",
      "\n",
      "    Combined Accuracy by Class:\n",
      "               class |    TP    FP    TN    FN     TPR      TNR      PPV      NPV       F1       TS \n",
      "                   0 |   861     0  4288     0  100.00%  100.00%  100.00%  100.00%  100.00%  100.00%\n",
      "                   1 |   772     0  4377     0  100.00%  100.00%  100.00%  100.00%  100.00%  100.00%\n",
      "                   2 |   703     0  4446     0  100.00%  100.00%  100.00%  100.00%  100.00%  100.00%\n",
      "                   3 |   850    26  4235    38   95.72%   99.11%   97.03%   99.11%   96.37%   93.00%\n",
      "                   4 |   944    40  4156     9   99.06%   99.78%   95.93%   99.78%   97.47%   95.07%\n",
      "                   5 |   949     4  4173    23   97.63%   99.45%   99.58%   99.45%   98.60%   97.23%\n",
      "\n",
      "    Attribute Ranking:\n",
      "                                  1 :   42.45%\n",
      "                                  4 :   22.34%\n",
      "                                  0 :   18.81%\n",
      "                                  2 :   12.90%\n",
      "                                  3 :    3.49%\n",
      "         \n",
      "\n",
      "\n",
      "\n",
      "End Time:           03/17/2021, 05:35 UTC\n",
      "Runtime Duration:   4m 8s\n",
      "Testing on heldout data using  RF -rank achieved 85.22% test accuracy\n",
      "##################################################\n",
      "Running: RF\n",
      "./btc 'train.csv' -headerless -f RF -o RF.py -riskoverfit --yes\n",
      "WARNING: Could not detect a GPU. Neural Network generation will be slow.\n",
      "\n",
      "\u001b[01;1mBrainome Table Compiler 0.991\u001b[0m\n",
      "Copyright (c) 2019-2021 Brainome, Inc. All Rights Reserved.\n",
      "Licensed to:                 Alexander Makhratchev  (Evaluation)\n",
      "Expiration Date:             2021-04-30   44 days left\n",
      "Maximum File Size:           30 GB\n",
      "Maximum Instances:           unlimited\n",
      "Maximum Attributes:          unlimited\n",
      "Maximum Classes:             unlimited\n",
      "Connected to:                daimensions.brainome.ai  (local execution)\n",
      "\n",
      "\u001b[01;1mCommand:\u001b[0m\n",
      "    btc train.csv -headerless -f RF -o RF.py -riskoverfit --yes\n",
      "\n",
      "Start Time:                 03/17/2021, 05:35 UTC\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[01;1mPre-training Measurements\u001b[0m\n",
      "Data:\n",
      "    Input:                      train.csv (headerless csv)\n",
      "    Target Column:              target\n",
      "    Number of instances:       5149\n",
      "    Number of attributes:       561 out of 561\n",
      "    Number of classes:            6\n",
      "\n",
      "Class Balance:                \n",
      "                               0: 16.72%\n",
      "                               1: 14.99%\n",
      "                               2: 13.65%\n",
      "                               3: 17.25%\n",
      "                               4: 18.51%\n",
      "                               5: 18.88%\n",
      "\n",
      "Learnability:\n",
      "    Best guess accuracy:          18.88%\n",
      "    Data Sufficiency:             Maybe enough data to generalize. [yellow]\n",
      "\n",
      "Capacity Progression:             at [ 5%, 10%, 20%, 40%, 80%, 100% ]\n",
      "    Ideal Machine Learner:              9,  10,  11,  11,  12,  12\n",
      "\n",
      "\n",
      "\n",
      "Expected Generalization:\n",
      "    Decision Tree:                 4.16 bits/bit\n",
      "    Neural Network:               41.93 bits/bit\n",
      "    Random Forest:                63.57 bits/bit\n",
      "\n",
      "Expected Accuracy:              Training            Validation\n",
      "    Decision Tree:               100.00%                38.10%\n",
      "    Neural Network:               99.42%                97.05%\n",
      "    Random Forest:               100.00%                96.86%\n",
      "\n",
      "Recommendations:\n",
      "    Note: Model type RF given by user. \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[01;1mPredictor:\u001b[0m                        RF.py\n",
      "    Classifier Type:              Random Forest\n",
      "    System Type:                  6-way classifier\n",
      "    Training / Validation Split:    Unable to split dataset. The predictor was trained and evaluated on the same data.\n",
      "    Accuracy:\n",
      "      Best-guess accuracy:        18.88%\n",
      "\n",
      "\n",
      "      Combined Model Accuracy:   100.00% (5149/5149 correct)\n",
      "\n",
      "    Model Capacity (MEC):          5    bits\n",
      "\n",
      "    Generalization Ratio:       2652.69 bits/bit\n",
      "    Generalization Index:        856.06\n",
      "    Percent of Data Memorized:     0.12%\n",
      "    Resilience to Noise:          -3.01 dB\n",
      "\n",
      "    Combined Confusion Matrix:\n",
      "              Actual | Predicted\n",
      "                   0 |   861     0     0     0     0     0 \n",
      "                   1 |     0   772     0     0     0     0 \n",
      "                   2 |     0     0   703     0     0     0 \n",
      "                   3 |     0     0     0   888     0     0 \n",
      "                   4 |     0     0     0     0   953     0 \n",
      "                   5 |     0     0     0     0     0   972 \n",
      "\n",
      "\n",
      "\n",
      "    Combined Accuracy by Class:\n",
      "               class |    TP    FP    TN    FN     TPR      TNR      PPV      NPV       F1       TS \n",
      "                   0 |   861     0  4288     0  100.00%  100.00%  100.00%  100.00%  100.00%  100.00%\n",
      "                   1 |   772     0  4377     0  100.00%  100.00%  100.00%  100.00%  100.00%  100.00%\n",
      "                   2 |   703     0  4446     0  100.00%  100.00%  100.00%  100.00%  100.00%  100.00%\n",
      "                   3 |   888     0  4261     0  100.00%  100.00%  100.00%  100.00%  100.00%  100.00%\n",
      "                   4 |   953     0  4196     0  100.00%  100.00%  100.00%  100.00%  100.00%  100.00%\n",
      "                   5 |   972     0  4177     0  100.00%  100.00%  100.00%  100.00%  100.00%  100.00%\n",
      "\n",
      "    Attribute Ranking:\n",
      "                                348 :   18.90%\n",
      "                                503 :    9.82%\n",
      "                                296 :    7.39%\n",
      "                                504 :    5.94%\n",
      "                                330 :    5.57%\n",
      "                                502 :    4.94%\n",
      "                                 52 :    4.94%\n",
      "                                 16 :    3.27%\n",
      "                                 40 :    2.97%\n",
      "                                129 :    2.36%\n",
      "                                 65 :    2.35%\n",
      "                                 50 :    2.14%\n",
      "                                352 :    1.78%\n",
      "                                  7 :    1.34%\n",
      "                                474 :    1.33%\n",
      "                                450 :    1.30%\n",
      "                                426 :    1.21%\n",
      "                                 69 :    1.17%\n",
      "                                537 :    1.06%\n",
      "                                316 :    1.01%\n",
      "                                166 :    0.90%\n",
      "                                445 :    0.65%\n",
      "                                302 :    0.62%\n",
      "                                 94 :    0.62%\n",
      "                                 38 :    0.62%\n",
      "                                 49 :    0.58%\n",
      "                                409 :    0.56%\n",
      "                                371 :    0.54%\n",
      "                                423 :    0.52%\n",
      "                                245 :    0.48%\n",
      "                                464 :    0.48%\n",
      "                                418 :    0.42%\n",
      "                                200 :    0.42%\n",
      "                                138 :    0.41%\n",
      "                                104 :    0.37%\n",
      "                                 75 :    0.37%\n",
      "                                174 :    0.37%\n",
      "                                  9 :    0.35%\n",
      "                                454 :    0.32%\n",
      "                                518 :    0.30%\n",
      "                                 54 :    0.29%\n",
      "                                310 :    0.28%\n",
      "                                 63 :    0.26%\n",
      "                                300 :    0.25%\n",
      "                                448 :    0.24%\n",
      "                                113 :    0.23%\n",
      "                                 74 :    0.22%\n",
      "                                101 :    0.19%\n",
      "                                 89 :    0.19%\n",
      "                                446 :    0.19%\n",
      "                                132 :    0.18%\n",
      "                                428 :    0.17%\n",
      "                                179 :    0.17%\n",
      "                                434 :    0.17%\n",
      "                                278 :    0.17%\n",
      "                                274 :    0.16%\n",
      "                                106 :    0.16%\n",
      "                                 37 :    0.16%\n",
      "                                209 :    0.14%\n",
      "                                 57 :    0.14%\n",
      "                                451 :    0.14%\n",
      "                                139 :    0.13%\n",
      "                                317 :    0.13%\n",
      "                                201 :    0.13%\n",
      "                                 22 :    0.12%\n",
      "                                369 :    0.12%\n",
      "                                419 :    0.12%\n",
      "                                432 :    0.12%\n",
      "                                142 :    0.11%\n",
      "                                 42 :    0.10%\n",
      "                                427 :    0.10%\n",
      "                                 61 :    0.09%\n",
      "                                429 :    0.09%\n",
      "                                557 :    0.09%\n",
      "                                196 :    0.09%\n",
      "                                 41 :    0.08%\n",
      "                                540 :    0.08%\n",
      "                                 53 :    0.08%\n",
      "                                449 :    0.08%\n",
      "                                510 :    0.08%\n",
      "                                 55 :    0.08%\n",
      "                                458 :    0.08%\n",
      "                                207 :    0.07%\n",
      "                                159 :    0.07%\n",
      "                                249 :    0.07%\n",
      "                                 45 :    0.07%\n",
      "                                141 :    0.07%\n",
      "                                527 :    0.07%\n",
      "                                184 :    0.07%\n",
      "                                558 :    0.06%\n",
      "                                 28 :    0.06%\n",
      "                                185 :    0.06%\n",
      "                                460 :    0.06%\n",
      "                                370 :    0.06%\n",
      "                                459 :    0.06%\n",
      "                                468 :    0.06%\n",
      "                                374 :    0.06%\n",
      "                                233 :    0.06%\n",
      "                                186 :    0.05%\n",
      "                                 58 :    0.05%\n",
      "                                433 :    0.05%\n",
      "                                298 :    0.05%\n",
      "                                 62 :    0.05%\n",
      "                                556 :    0.04%\n",
      "                                390 :    0.04%\n",
      "                                351 :    0.04%\n",
      "                                297 :    0.04%\n",
      "                                243 :    0.04%\n",
      "                                265 :    0.04%\n",
      "                                 78 :    0.04%\n",
      "                                136 :    0.04%\n",
      "                                198 :    0.04%\n",
      "                                373 :    0.04%\n",
      "                                 73 :    0.03%\n",
      "                                322 :    0.03%\n",
      "                                102 :    0.03%\n",
      "                                127 :    0.03%\n",
      "                                487 :    0.03%\n",
      "                                199 :    0.03%\n",
      "                                381 :    0.03%\n",
      "                                112 :    0.03%\n",
      "                                270 :    0.03%\n",
      "                                172 :    0.03%\n",
      "                                133 :    0.03%\n",
      "                                 36 :    0.03%\n",
      "                                 46 :    0.03%\n",
      "                                291 :    0.03%\n",
      "                                160 :    0.03%\n",
      "                                 23 :    0.03%\n",
      "                                309 :    0.02%\n",
      "                                126 :    0.02%\n",
      "                                148 :    0.02%\n",
      "                                331 :    0.02%\n",
      "                                301 :    0.02%\n",
      "                                248 :    0.02%\n",
      "                                461 :    0.02%\n",
      "                                121 :    0.02%\n",
      "                                119 :    0.02%\n",
      "                                551 :    0.02%\n",
      "                                150 :    0.02%\n",
      "                                187 :    0.02%\n",
      "                                204 :    0.02%\n",
      "                                197 :    0.02%\n",
      "                                285 :    0.02%\n",
      "                                295 :    0.02%\n",
      "                                140 :    0.02%\n",
      "                                385 :    0.02%\n",
      "                                505 :    0.02%\n",
      "                                202 :    0.02%\n",
      "                                143 :    0.02%\n",
      "                                 91 :    0.02%\n",
      "                                275 :    0.02%\n",
      "                                162 :    0.02%\n",
      "                                247 :    0.02%\n",
      "                                 80 :    0.01%\n",
      "                                383 :    0.01%\n",
      "                                115 :    0.01%\n",
      "                                194 :    0.01%\n",
      "                                 24 :    0.01%\n",
      "                                149 :    0.01%\n",
      "                                456 :    0.01%\n",
      "                                511 :    0.01%\n",
      "                                117 :    0.01%\n",
      "                                299 :    0.01%\n",
      "                                235 :    0.01%\n",
      "                                114 :    0.01%\n",
      "                                268 :    0.01%\n",
      "                                267 :    0.01%\n",
      "                                118 :    0.01%\n",
      "                                 77 :    0.01%\n",
      "                                329 :    0.01%\n",
      "                                457 :    0.01%\n",
      "                                 92 :    0.01%\n",
      "                                372 :    0.01%\n",
      "                                286 :    0.01%\n",
      "                                158 :    0.01%\n",
      "                                 43 :    0.01%\n",
      "                                103 :    0.01%\n",
      "                                  1 :    0.01%\n",
      "                                271 :    0.01%\n",
      "                                358 :    0.01%\n",
      "                                 51 :    0.01%\n",
      "                                228 :    0.01%\n",
      "                                190 :    0.01%\n",
      "                                 35 :    0.01%\n",
      "                                526 :    0.01%\n",
      "                                236 :    0.01%\n",
      "                                161 :    0.01%\n",
      "                                 79 :    0.01%\n",
      "                                354 :    0.01%\n",
      "                                145 :    0.00%\n",
      "                                122 :    0.00%\n",
      "                                416 :    0.00%\n",
      "                                116 :    0.00%\n",
      "                                 13 :    0.00%\n",
      "                                413 :    0.00%\n",
      "                                 56 :    0.00%\n",
      "                                212 :    0.00%\n",
      "                                134 :    0.00%\n",
      "                                157 :    0.00%\n",
      "                                163 :    0.00%\n",
      "                                528 :    0.00%\n",
      "                                108 :    0.00%\n",
      "                                130 :    0.00%\n",
      "                                180 :    0.00%\n",
      "                                 39 :    0.00%\n",
      "                                363 :    0.00%\n",
      "                                 76 :    0.00%\n",
      "                                250 :    0.00%\n",
      "                                379 :    0.00%\n",
      "                                  6 :    0.00%\n",
      "                                365 :    0.00%\n",
      "                                559 :    0.00%\n",
      "                                171 :    0.00%\n",
      "                                466 :    0.00%\n",
      "                                110 :    0.00%\n",
      "                                 85 :    0.00%\n",
      "                                 12 :    0.00%\n",
      "                                273 :    0.00%\n",
      "                                120 :    0.00%\n",
      "                                152 :    0.00%\n",
      "                                 64 :    0.00%\n",
      "                                519 :    0.00%\n",
      "                                 71 :    0.00%\n",
      "                                 67 :    0.00%\n",
      "                                555 :    0.00%\n",
      "                                380 :    0.00%\n",
      "                                560 :    0.00%\n",
      "                                 72 :    0.00%\n",
      "                                128 :    0.00%\n",
      "                                230 :    0.00%\n",
      "                                251 :    0.00%\n",
      "                                444 :    0.00%\n",
      "                                318 :    0.00%\n",
      "                                455 :    0.00%\n",
      "                                 25 :    0.00%\n",
      "                                453 :    0.00%\n",
      "                                  0 :    0.00%\n",
      "                                105 :    0.00%\n",
      "                                261 :    0.00%\n",
      "                                264 :    0.00%\n",
      "                                338 :    0.00%\n",
      "                                452 :    0.00%\n",
      "                                192 :    0.00%\n",
      "                                525 :    0.00%\n",
      "                                 59 :    0.00%\n",
      "                                479 :    0.00%\n",
      "                                182 :    0.00%\n",
      "                                375 :    0.00%\n",
      "                                495 :    0.00%\n",
      "                                544 :    0.00%\n",
      "                                263 :    0.00%\n",
      "                                538 :    0.00%\n",
      "                                524 :    0.00%\n",
      "                                 68 :    0.00%\n",
      "                                539 :    0.00%\n",
      "                                412 :    0.00%\n",
      "                                156 :    0.00%\n",
      "                                246 :    0.00%\n",
      "                                550 :    0.00%\n",
      "                                506 :    0.00%\n",
      "                                195 :    0.00%\n",
      "                                279 :    0.00%\n",
      "                                447 :    0.00%\n",
      "                                294 :    0.00%\n",
      "                                  2 :    0.00%\n",
      "                                553 :    0.00%\n",
      "                                144 :    0.00%\n",
      "                                 32 :    0.00%\n",
      "                                210 :    0.00%\n",
      "                                473 :    0.00%\n",
      "                                155 :    0.00%\n",
      "                                 66 :    0.00%\n",
      "                                238 :    0.00%\n",
      "                                167 :    0.00%\n",
      "                                292 :    0.00%\n",
      "                                 84 :    0.00%\n",
      "         \n",
      "\n",
      "\n",
      "\n",
      "End Time:           03/17/2021, 05:37 UTC\n",
      "Runtime Duration:   2m 30s\n",
      "Testing on heldout data using  RF achieved 98.54% test accuracy\n",
      "##################################################\n",
      "Running: NN\n",
      "./btc 'train.csv' -headerless -f NN -o NN.py -riskoverfit --yes\n",
      "WARNING: Could not detect a GPU. Neural Network generation will be slow.\n",
      "\n",
      "\u001b[01;1mBrainome Table Compiler 0.991\u001b[0m\n",
      "Copyright (c) 2019-2021 Brainome, Inc. All Rights Reserved.\n",
      "Licensed to:                 Alexander Makhratchev  (Evaluation)\n",
      "Expiration Date:             2021-04-30   44 days left\n",
      "Maximum File Size:           30 GB\n",
      "Maximum Instances:           unlimited\n",
      "Maximum Attributes:          unlimited\n",
      "Maximum Classes:             unlimited\n",
      "Connected to:                daimensions.brainome.ai  (local execution)\n",
      "\n",
      "\u001b[01;1mCommand:\u001b[0m\n",
      "    btc train.csv -headerless -f NN -o NN.py -riskoverfit --yes\n",
      "\n",
      "Start Time:                 03/17/2021, 05:37 UTC\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[01;1mPre-training Measurements\u001b[0m\n",
      "Data:\n",
      "    Input:                      train.csv (headerless csv)\n",
      "    Target Column:              target\n",
      "    Number of instances:       5149\n",
      "    Number of attributes:       561 out of 561\n",
      "    Number of classes:            6\n",
      "\n",
      "Class Balance:                \n",
      "                               0: 16.72%\n",
      "                               1: 14.99%\n",
      "                               2: 13.65%\n",
      "                               3: 17.25%\n",
      "                               4: 18.51%\n",
      "                               5: 18.88%\n",
      "\n",
      "Learnability:\n",
      "    Best guess accuracy:          18.88%\n",
      "    Data Sufficiency:             Maybe enough data to generalize. [yellow]\n",
      "\n",
      "Capacity Progression:             at [ 5%, 10%, 20%, 40%, 80%, 100% ]\n",
      "    Ideal Machine Learner:              9,  10,  11,  11,  12,  12\n",
      "\n",
      "\n",
      "\n",
      "Expected Generalization:\n",
      "    Decision Tree:                 4.16 bits/bit\n",
      "    Neural Network:               41.93 bits/bit\n",
      "    Random Forest:                63.57 bits/bit\n",
      "\n",
      "Expected Accuracy:              Training            Validation\n",
      "    Decision Tree:               100.00%                38.10%\n",
      "    Neural Network:               99.42%                97.05%\n",
      "    Random Forest:               100.00%                96.86%\n",
      "\n",
      "Recommendations:\n",
      "    Note: Model type NN given by user. \n",
      "\n",
      "Time to Build Estimates:\n",
      "    Neural Network:                 35 minutes\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[01;1mPredictor:\u001b[0m                        NN.py\n",
      "    Classifier Type:              Neural Network\n",
      "    System Type:                  6-way classifier\n",
      "    Training / Validation Split:    Unable to split dataset. The predictor was trained and evaluated on the same data.\n",
      "    Accuracy:\n",
      "      Best-guess accuracy:        18.88%\n",
      "\n",
      "\n",
      "      Combined Model Accuracy:    99.96% (5147/5149 correct)\n",
      "\n",
      "    Model Capacity (MEC):       3414    bits\n",
      "    Model Capacity Utilized:    3414    bits \n",
      "    Generalization Ratio:          3.86 bits/bit\n",
      "    Generalization Index:          1.25\n",
      "    Percent of Data Memorized:    80.20%\n",
      "    Resilience to Noise:          -0.18 dB\n",
      "\n",
      "    Combined Confusion Matrix:\n",
      "              Actual | Predicted\n",
      "                   0 |   861     0     0     0     0     0 \n",
      "                   1 |     0   772     0     0     0     0 \n",
      "                   2 |     0     0   703     0     0     0 \n",
      "                   3 |     0     0     0   887     1     0 \n",
      "                   4 |     0     0     0     1   952     0 \n",
      "                   5 |     0     0     0     0     0   972 \n",
      "\n",
      "\n",
      "\n",
      "    Combined Accuracy by Class:\n",
      "               class |    TP    FP    TN    FN     TPR      TNR      PPV      NPV       F1       TS \n",
      "                   0 |   861     0  4288     0  100.00%  100.00%  100.00%  100.00%  100.00%  100.00%\n",
      "                   1 |   772     0  4377     0  100.00%  100.00%  100.00%  100.00%  100.00%  100.00%\n",
      "                   2 |   703     0  4446     0  100.00%  100.00%  100.00%  100.00%  100.00%  100.00%\n",
      "                   3 |   887     1  4260     1   99.89%   99.98%   99.89%   99.98%   99.89%   99.78%\n",
      "                   4 |   952     1  4195     1   99.90%   99.98%   99.90%   99.98%   99.90%   99.79%\n",
      "                   5 |   972     0  4177     0  100.00%  100.00%  100.00%  100.00%  100.00%  100.00%\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "End Time:           03/17/2021, 05:51 UTC\n",
      "Runtime Duration:   13m 59s\n",
      "Testing on heldout data using  NN achieved 97.88% test accuracy\n",
      "##################################################\n",
      "Running: DT\n",
      "./btc 'train.csv' -headerless -f DT -o DT.py -riskoverfit --yes\n",
      "WARNING: Could not detect a GPU. Neural Network generation will be slow.\n",
      "\n",
      "\u001b[01;1mBrainome Table Compiler 0.991\u001b[0m\n",
      "Copyright (c) 2019-2021 Brainome, Inc. All Rights Reserved.\n",
      "Licensed to:                 Alexander Makhratchev  (Evaluation)\n",
      "Expiration Date:             2021-04-30   44 days left\n",
      "Maximum File Size:           30 GB\n",
      "Maximum Instances:           unlimited\n",
      "Maximum Attributes:          unlimited\n",
      "Maximum Classes:             unlimited\n",
      "Connected to:                daimensions.brainome.ai  (local execution)\n",
      "\n",
      "\u001b[01;1mCommand:\u001b[0m\n",
      "    btc train.csv -headerless -f DT -o DT.py -riskoverfit --yes\n",
      "\n",
      "Start Time:                 03/17/2021, 05:52 UTC\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[01;1mPre-training Measurements\u001b[0m\n",
      "Data:\n",
      "    Input:                      train.csv (headerless csv)\n",
      "    Target Column:              target\n",
      "    Number of instances:       5149\n",
      "    Number of attributes:       561 out of 561\n",
      "    Number of classes:            6\n",
      "\n",
      "Class Balance:                \n",
      "                               0: 16.72%\n",
      "                               1: 14.99%\n",
      "                               2: 13.65%\n",
      "                               3: 17.25%\n",
      "                               4: 18.51%\n",
      "                               5: 18.88%\n",
      "\n",
      "Learnability:\n",
      "    Best guess accuracy:          18.88%\n",
      "    Data Sufficiency:             Maybe enough data to generalize. [yellow]\n",
      "\n",
      "Capacity Progression:             at [ 5%, 10%, 20%, 40%, 80%, 100% ]\n",
      "    Ideal Machine Learner:              9,  10,  11,  11,  12,  12\n",
      "\n",
      "\n",
      "\n",
      "Expected Generalization:\n",
      "    Decision Tree:                 4.16 bits/bit\n",
      "    Neural Network:               41.93 bits/bit\n",
      "    Random Forest:                63.57 bits/bit\n",
      "\n",
      "Expected Accuracy:              Training            Validation\n",
      "    Decision Tree:               100.00%                38.10%\n",
      "    Neural Network:               99.42%                97.05%\n",
      "    Random Forest:               100.00%                96.86%\n",
      "\n",
      "Recommendations:\n",
      "    Note: Model type DT given by user. \n",
      "\n",
      "Time to Build Estimates:\n",
      "    Decision Tree:                a few seconds\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[01;1mPredictor:\u001b[0m                        DT.py\n",
      "    Classifier Type:              Decision Tree\n",
      "    System Type:                  6-way classifier\n",
      "    Training / Validation Split:    Unable to split dataset. The predictor was trained and evaluated on the same data.\n",
      "    Accuracy:\n",
      "      Best-guess accuracy:        18.88%\n",
      "\n",
      "\n",
      "      Combined Model Accuracy:    99.98% (5148/5149 correct)\n",
      "\n",
      "    Model Capacity (MEC):       3187    bits\n",
      "\n",
      "    Generalization Ratio:          4.15 bits/bit\n",
      "    Generalization Index:          1.34\n",
      "    Percent of Data Memorized:    74.72%\n",
      "    Resilience to Noise:          -0.21 dB\n",
      "\n",
      "    Combined Confusion Matrix:\n",
      "              Actual | Predicted\n",
      "                   0 |   861     0     0     0     0     0 \n",
      "                   1 |     1   771     0     0     0     0 \n",
      "                   2 |     0     0   703     0     0     0 \n",
      "                   3 |     0     0     0   888     0     0 \n",
      "                   4 |     0     0     0     0   953     0 \n",
      "                   5 |     0     0     0     0     0   972 \n",
      "\n",
      "\n",
      "\n",
      "    Combined Accuracy by Class:\n",
      "               class |    TP    FP    TN    FN     TPR      TNR      PPV      NPV       F1       TS \n",
      "                   0 |   861     1  4287     0  100.00%  100.00%   99.88%  100.00%   99.94%   99.88%\n",
      "                   1 |   771     0  4377     1   99.87%   99.98%  100.00%   99.98%   99.94%   99.87%\n",
      "                   2 |   703     0  4446     0  100.00%  100.00%  100.00%  100.00%  100.00%  100.00%\n",
      "                   3 |   888     0  4261     0  100.00%  100.00%  100.00%  100.00%  100.00%  100.00%\n",
      "                   4 |   953     0  4196     0  100.00%  100.00%  100.00%  100.00%  100.00%  100.00%\n",
      "                   5 |   972     0  4177     0  100.00%  100.00%  100.00%  100.00%  100.00%  100.00%\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "End Time:           03/17/2021, 05:53 UTC\n",
      "Runtime Duration:   1m 43s\n",
      "Testing on heldout data using  DT achieved 37.36% test accuracy\n",
      "##################################################\n",
      "Done Running!\n",
      "Summary:\n",
      "{'DT -rank': 62.17, 'NN -rank': 83.67, 'RF -rank': 85.22, 'RF': 98.54, 'NN': 97.88, 'DT': 37.36}\n",
      "Best Test Accuracy: 98.54\n",
      "Using: RF\n",
      "Total Time Elapsed: 2068 seconds\n",
      "Error while deleting file :  clean051920316141.csv\n",
      "Error while deleting file :  clean.state\n"
     ]
    }
   ],
   "source": [
    "! python3 tryall.py phone_activity.csv btc"
   ]
  },
  {
   "source": [
    "### Accuracy on Validation for Each Model:\n",
    "Best Guess: 22.82%\n",
    "\n",
    "DT -rank: 62.17%\n",
    "\n",
    "NN -rank: 83.67%\n",
    "\n",
    "RF -rank: 85.17%\n",
    "\n",
    "DT: 37.36%\n",
    "\n",
    "NN: 97.88%\n",
    "\n",
    "RF: 98.45% \n",
    "\n",
    "The random forest model worked the best with 98.45% accuracy, with the neural network followed closely behind. However the tryall script does take a while to run, especially on larger datasets.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Citation:\n",
    "UCI Machine Learning Repository Davide Anguita, Alessandro Ghio, Luca Oneto, Xavier Parra and Jorge L. Reyes-Ortiz. \n",
    "A Public Domain Dataset for Human Activity Recognition Using Smartphones. \n",
    "21th European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning, ESANN 2013. \n",
    "Bruges, Belgium 24-26 April 2013. Jorge L. Reyes-Ortiz(1,2), Davide Anguita(1), Alessandro Ghio(1), Luca Oneto(1) and Xavier Parra(2) 1 - Smartlab - Non-Linear Complex Systems Laboratory DITEN - Universit degli Studi di Genova, Genoa (I-16145), Italy. 2 - CETpD - Technical Research Centre for Dependency Care and Autonomous Living Universitat Politcnica de Catalunya (BarcelonaTech). \n",
    "Vilanova i la Geltr (08800), Spain activityrecognition '@' smartlab.ws"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}