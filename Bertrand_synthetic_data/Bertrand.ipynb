{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificially-Created Data Prediction Using Daimensions\n",
    "\n",
    "This dataset was artificially created with a specific rule in mind. The goal of this notebook is to show how Daimensions handles data created by a specified rule. Bertrand, the cofounder of Brainome, made this dataset, so the csv's are named after him."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1,1,0,0,0,0,0,0,0,1,1\n1,1,1,0,0,1,0,1,0,1,0\n0,1,0,1,0,1,0,0,0,1,0\n0,0,1,1,0,1,0,1,0,1,1\n0,0,1,0,0,0,1,0,1,1,1\n0,0,1,1,1,1,0,0,1,1,0\n0,0,1,1,1,1,0,0,0,0,0\n0,0,1,0,0,1,1,0,1,1,1\n1,1,1,0,1,1,1,1,0,0,1\n0,0,0,0,1,0,1,0,0,1,1\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "head bertrandtrain.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see from above, this data doesn't have column names. Because of this, we have to use -headerless when measuring our data and building our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Get Measurements\n",
    "\n",
    "We always want to measure our data before building our predictor in order to ensure we are building the right model. For more information about how to use Daimensions and why we want to measure our data beforehand, check out the Titanic notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING: Could not detect a GPU. Neural Network generation will be slow.\n",
      "\n",
      "Brainome Daimensions(tm) 0.99 Copyright (c) 2019 - 2021 by Brainome, Inc. All Rights Reserved.\n",
      "Licensed to:              Alexander Makhratchev  (Evaluation)\n",
      "Expiration Date:          2021-04-30   56 days left\n",
      "Number of Threads:        1\n",
      "Maximum File Size:        30 GB\n",
      "Maximum Instances:        unlimited\n",
      "Maximum Attributes:       unlimited\n",
      "Maximum Classes:          unlimited\n",
      "Connected to:             daimensions.brainome.ai  (local execution)\n",
      "\n",
      "\n",
      "\n",
      "Command:\n",
      "    btc -measureonly bertrandtrain.csv -headerless\n",
      "\n",
      "Start Time:                 03/05/2021, 17:50\n",
      "\n",
      "\n",
      "Data:\n",
      "    Input:                      bertrandtrain.csv (headerless csv)\n",
      "    Target Column:              target\n",
      "    Number of instances:        13187\n",
      "    Number of attributes:       10\n",
      "    Number of classes:          2\n",
      "    Class Balance:              0: 37.35%, 1: 62.65%\n",
      "\n",
      "Learnability:\n",
      "    Best guess accuracy:          62.65%\n",
      "    Data Sufficiency:            Not enough data to generalize. [red]\n",
      "\n",
      "Capacity Progression:            at [ 5%, 10%, 20%, 40%, 80%, 100% ]\n",
      "    Optimal Machine Learner:           9,  10,  11,  12,  12,  13\n",
      "\n",
      "\n",
      "Estimated Memory Equivalent Capacity for...\n",
      "    Decision Tree:                     1 parameters\n",
      "    Neural Networks:                   1 parameters\n",
      "    Random Forest:                     1 parameters\n",
      "\n",
      "Risk that model needs to overfit for 100% accuracy using...\n",
      "    Decision Tree:                 0.03%\n",
      "    Neural Networks:               0.97%\n",
      "    Random Forest:                 0.04%\n",
      "\n",
      "Expected Generalization using...\n",
      "    Decision Tree:               7952.45 bits/bit\n",
      "    Neural Network:              6593.00 bits/bit\n",
      "    Random Forest:              13187.00 bits/bit\n",
      "\n",
      "\n",
      "Recommendations:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Time to Build Estimates:\n",
      "    Decision Tree:             less than a minute\n",
      "    Neural Network:              4 minutes\n",
      "\n",
      "\n",
      "\u001b[1A\u001b[1B\u001b[0G\u001b[?25l[+] Building 0.0s (0/1)                                                         \n",
      "\u001b[?25h\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.1s (2/2)                                                         \n",
      "\u001b[34m => [internal] load build definition from btc-dockerfile.12266             0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 239B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.2s (3/7)                                                         \n",
      "\u001b[34m => [internal] load build definition from btc-dockerfile.12266             0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 239B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/brainome/btc_local_cpu:alpha    0.0s\n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.4s (7/8)                                                         \n",
      "\u001b[34m => [internal] load build definition from btc-dockerfile.12266             0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 239B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/brainome/btc_local_cpu:alpha    0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.1s\n",
      "\u001b[0m\u001b[34m => => transferring context: 1.37kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => [1/3] FROM docker.io/brainome/btc_local_cpu:alpha                      0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/3] RUN adduser --disabled-password --gecos '' --uid 501 --g  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [3/3] COPY --chown=501:20 .daimensions.key /btc-alex            0.0s\n",
      "\u001b[0m => exporting to image                                                     0.1s\n",
      "\u001b[34m => => exporting layers                                                    0.0s\n",
      "\u001b[0m => => writing image sha256:43dd56f18fcffcdd02c290bfcce87c7a6cd0b9ccf4db3  0.0s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.4s (8/8) FINISHED                                                \n",
      "\u001b[34m => [internal] load build definition from btc-dockerfile.12266             0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 239B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/brainome/btc_local_cpu:alpha    0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.1s\n",
      "\u001b[0m\u001b[34m => => transferring context: 1.37kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => [1/3] FROM docker.io/brainome/btc_local_cpu:alpha                      0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/3] RUN adduser --disabled-password --gecos '' --uid 501 --g  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [3/3] COPY --chown=501:20 .daimensions.key /btc-alex            0.0s\n",
      "\u001b[0m\u001b[34m => exporting to image                                                     0.1s\n",
      "\u001b[0m\u001b[34m => => exporting layers                                                    0.0s\n",
      "\u001b[0m\u001b[34m => => writing image sha256:43dd56f18fcffcdd02c290bfcce87c7a6cd0b9ccf4db3  0.0s\n",
      "\u001b[0m\u001b[34m => => naming to docker.io/library/btc-alex:latest                         0.0s\n",
      "\u001b[0m\u001b[?25hDocker image btc-alex:latest updated successfully.\n"
     ]
    }
   ],
   "source": [
    "! btc -measureonly bertrandtrain.csv -headerless"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build the Predictor\n",
    "\n",
    "Based on our measurements, Daimensions recommends we use a neural network, which has 83.99 bits/bit of expected generalization for this dataset. Don't forget to use -headerless."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING: Could not detect a GPU. Neural Network generation will be slow.\n",
      "\n",
      "Brainome Daimensions(tm) 0.99 Copyright (c) 2019 - 2021 by Brainome, Inc. All Rights Reserved.\n",
      "Licensed to:              Alexander Makhratchev  (Evaluation)\n",
      "Expiration Date:          2021-04-30   56 days left\n",
      "Number of Threads:        1\n",
      "Maximum File Size:        30 GB\n",
      "Maximum Instances:        unlimited\n",
      "Maximum Attributes:       unlimited\n",
      "Maximum Classes:          unlimited\n",
      "Connected to:             daimensions.brainome.ai  (local execution)\n",
      "\n",
      "\n",
      "\n",
      "Command:\n",
      "    btc -f NN bertrandtrain.csv -o bertrand_predict.py -headerless -e 10 --yes\n",
      "\n",
      "Start Time:                 03/05/2021, 17:52\n",
      "\n",
      "\n",
      "Data:\n",
      "    Input:                      bertrandtrain.csv (headerless csv)\n",
      "    Target Column:              target\n",
      "    Number of instances:        13187\n",
      "    Number of attributes:       10\n",
      "    Number of classes:          2\n",
      "    Class Balance:              0: 37.35%, 1: 62.65%\n",
      "\n",
      "Learnability:\n",
      "    Best guess accuracy:          62.65%\n",
      "    Data Sufficiency:            Not enough data to generalize. [red]\n",
      "\n",
      "Capacity Progression:            at [ 5%, 10%, 20%, 40%, 80%, 100% ]\n",
      "    Optimal Machine Learner:           9,  10,  11,  12,  12,  13\n",
      "\n",
      "\n",
      "Estimated Memory Equivalent Capacity for...\n",
      "    Decision Tree:                     1 parameters\n",
      "    Neural Networks:                   1 parameters\n",
      "    Random Forest:                     1 parameters\n",
      "\n",
      "Risk that model needs to overfit for 100% accuracy using...\n",
      "    Decision Tree:                 0.03%\n",
      "    Neural Networks:               0.97%\n",
      "    Random Forest:                 0.04%\n",
      "\n",
      "Expected Generalization using...\n",
      "    Decision Tree:               7952.45 bits/bit\n",
      "    Neural Network:              6593.00 bits/bit\n",
      "    Random Forest:              13187.00 bits/bit\n",
      "\n",
      "\n",
      "Recommendations:\n",
      "\n",
      "\n",
      "    Note: Machine learner type NN given by user.\n",
      "\n",
      "\n",
      "Time to Build Estimates:\n",
      "\n",
      "    Neural Network:              2 minutes\n",
      "\n",
      "\n",
      "\n",
      "System Meter:                          bertrand_predict.py\n",
      "    Classifier Type:                   Neural Network\n",
      "    System Type:                       Binary classifier\n",
      "    Training/Validation Split:           50% : 50%\n",
      "    Accuracy:\n",
      "        Best-guess accuracy:               62.65%\n",
      "        Training accuracy:                100.00% (6593/6593 correct)\n",
      "        Validation Accuracy:              100.00% (6594/6594 correct)\n",
      "        Overall Model Accuracy:           100.00% (13187/13187 correct)\n",
      "        Improvement over best guess:       37.35% of possible  37.35%\n",
      "\n",
      "    Model Capacity (MEC):                       1 bit\n",
      "    Generalization Ratio:                 6275.10 bits/bit\n",
      "    Model Efficiency:                       37.35 /parameter\n",
      "    Generalization Index:                 3080.49\n",
      "    Percent of Data Memorized:               0.03%\n",
      "\n",
      "    Training Confusion Matrix (count):\n",
      "                   0 |   2449      0 \n",
      "                   1 |      0   4144 \n",
      "\n",
      "    Validation Confusion Matrix (count):\n",
      "                   0 |   2476      0 \n",
      "                   1 |      0   4118 \n",
      "\n",
      "    Full Confusion Matrix (count):\n",
      "                   0 |   4925      0 \n",
      "                   1 |      0   8262 \n",
      "\n",
      "    Accuracy by Class:\n",
      "               class |     TP     FP     TN     FN     TPR      TNR      PPV      NPV       F1       TS \n",
      "                   0 |   4925      0   8262      0  100.00%  100.00%  100.00%  100.00%  100.00%  100.00%\n",
      "                   1 |   8262      0   4925      0  100.00%  100.00%  100.00%  100.00%  100.00%  100.00%\n",
      "\n",
      "End Time:                     \n",
      "Runtime Duration:             \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! btc -f NN bertrandtrain.csv -o bertrand_predict.py -headerless -e 10 --yes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Make a Prediction\n",
    "\n",
    "Hooray! Our model has 100% accuracy. Now we can use our model to make predictions on test data, a separate set of data that wasn't used for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0,0,1,1,0,1,1,0,0,0,Prediction\n1,0,0,0,1,0,0,1,1,0,0\n0,0,1,1,1,0,0,1,0,0,0\n1,0,0,0,1,1,0,0,1,1,0\n1,1,0,1,1,0,1,1,1,1,1\n0,0,0,0,0,1,1,0,0,1,0\n0,0,0,0,1,1,1,0,1,1,1\n0,1,0,0,0,0,1,0,1,0,1\n0,1,1,1,1,1,0,0,1,0,0\n0,1,0,1,0,0,0,1,0,1,0\n"
     ]
    }
   ],
   "source": [
    "! python3 bertrand_predict.py bertrandtest.csv > bertrand_prediction.csv\n",
    "! head bertrand_prediction.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}