{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificially-Created Data Prediction Using Daimensions\n",
    "\n",
    "This dataset was artificially created with a specific rule in mind. The goal of this notebook is to show how Daimensions handles data created by a specified rule. Bertrand, the cofounder of Brainome, made this dataset, so the csv's are named after him."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "! bertrandtrain.csv | more\n"
     },
     "metadata": {}
    }
   ],
   "source": [
    "%%markdown\n",
    "! bertrandtrain.csv | more"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see from above, this data doesn't have column names. Because of this, we have to use -headerless when measuring our data and building our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Get Measurements\n",
    "\n",
    "We always want to measure our data before building our predictor in order to ensure we are building the right model. For more information about how to use Daimensions and why we want to measure our data beforehand, check out the Titanic notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Brainome Daimensions(tm) 0.991 Copyright (c) 2019, 2020 by Brainome, Inc. All Rights Reserved.\nExpiration date: 2021-04-30 (66 days left)\nNumber of threads: 1\nMaximum file size: 30720MB\nRunning locally.\nWARNING: Could not detect a GPU. Neural Network generation will be slow.\n\nData:\nNumber of instances: 13187\nNumber of attributes: 10\nNumber of classes: 2\nClass balance: 37.35% 62.65%\n\nLearnability:\nBest guess accuracy: 62.65%\nCapacity progression: [11, 13, 14, 15, 15, 16]\nDecision Tree: 1 parameters\nEstimate Memory Equivalent Capacity for Random Forests: 4 parameters\nEstimated Memory Equivalent Capacity for Neural Networks: 157 parameters\n\nRisk that model needs to overfit for 100% accuracy...\nusing Decision Tree: 0.03%\nusing Random Forests: 0.05%\nusing Neural Networks: 100.00%\n\nExpected Generalization...\nusing Decision Tree: 7952.45 bits/bit\nusing Random Forests: 3296.75 bits/bit\nusing a Neural Network: 80.07 bits/bit\n\nRecommendations:\nWarning: Not enough data to generalize. [red]\nNote: Decision Tree clustering may outperform Neural Networks. Try with -f DT.\nTime estimate for a Neural Network:\nEstimated time to architect: 0d 0h 0m 10s\n\nEstimated time to prime (subject to change after model architecting): 0d 0h 0m 51s\n\nTime estimate for Decision Tree:\nEstimated time to prime a decision tree: less than a minute\n"
     ]
    }
   ],
   "source": [
    "! btc -measureonly bertrandtrain.csv -headerless"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build the Predictor\n",
    "\n",
    "Based on our measurements, Daimensions recommends we use a neural network, which has 83.99 bits/bit of expected generalization for this dataset. Don't forget to use -headerless."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Brainome Daimensions(tm) 0.991 Copyright (c) 2019, 2020 by Brainome, Inc. All Rights Reserved.\nExpiration date: 2021-04-30 (66 days left)\nNumber of threads: 1\nMaximum file size: 30720MB\nRunning locally.\nWARNING: Could not detect a GPU. Neural Network generation will be slow.\n\nData:\nNumber of instances: 13187\nNumber of attributes: 10\nNumber of classes: 2\nClass balance: 37.35% 62.65%\n\nLearnability:\nBest guess accuracy: 62.65%\nCapacity progression: [11, 13, 14, 15, 15, 16]\nDecision Tree: 1 parameters\nEstimate Memory Equivalent Capacity for Random Forests: 4 parameters\nEstimated Memory Equivalent Capacity for Neural Networks: 157 parameters\n\nRisk that model needs to overfit for 100% accuracy...\nusing Decision Tree: 0.03%\nusing Random Forests: 0.05%\nusing Neural Networks: 100.00%\n\nExpected Generalization...\nusing Decision Tree: 7952.45 bits/bit\nusing Random Forests: 3296.75 bits/bit\nusing a Neural Network: 80.07 bits/bit\n\nRecommendations:\nWarning: Not enough data to generalize. [red]\nNote: Decision Tree clustering may outperform Neural Networks. Try with -f DT.\nTime estimate for a Neural Network:\nEstimated time to architect: 0d 0h 0m 11s\n\nEstimated time to prime (subject to change after model architecting): 0d 0h 0m 52s\n\nNote: Machine learner type NN given by user.\nModel capacity (MEC):     49 bits\nArchitecture efficiency:   1.0 bits/parameter\n\nEstimated time to prime model: 0d 0h 0m 51s\n\nPriming model...done.\nEstimated training time: 0d 0h 8m 47s\n\nTraining...done.\nClassifier Type:                    Neural Network\nSystem Type:                         Binary classifier\nTraining/Validation Split:           50:50%\nBest-guess accuracy:                 62.65%\nTraining accuracy:                   100.00% (6593/6593 correct)\nValidation accuracy:                 100.00% (6594/6594 correct)\nOverall Model accuracy:              100.00% (13187/13187 correct)\nOverall Improvement over best guess: 37.35% (of possible 37.35%)\nModel capacity (MEC):                61 bits\nGeneralization ratio:                102.69 bits/bit\nModel efficiency:                    0.61%/parameter\nSystem behavior\nTrue Negatives:                      37.35% (4925/13187)\nTrue Positives:                      62.65% (8262/13187)\nFalse Negatives:                     0.00% (0/13187)\nFalse Positives:                     0.00% (0/13187)\nTrue Pos. Rate/Sensitivity/Recall:   1.00\nTrue Neg. Rate/Specificity:          1.00\nPrecision:                           1.00\nF-1 Measure:                         1.00\nFalse Negative Rate/Miss Rate:       0.00\nCritical Success Index:              1.00\nConfusion Matrix:\n [37.35% 0.00%]\n [0.00% 62.65%]\nGeneralization index:           50.41\nOverfitting:                         No\n \n"
     ]
    }
   ],
   "source": [
    "! btc -f NN bertrandtrain.csv -o bertrand_predict.py -headerless -e 10 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Make a Prediction\n",
    "\n",
    "Hooray! Our model has 100% accuracy. Now we can use our model to make predictions on test data, a separate set of data that wasn't used for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0,0,1,1,0,1,1,0,0,0,Prediction\r\n",
      "0,0,0,0,0,0,0,0,0,0,0\r\n",
      "0,0,0,0,0,0,0,0,0,0,0\r\n",
      "1,1,0,0,1,0,0,1,1,1,0\r\n",
      "1,1,1,1,1,1,1,1,1,1,1\r\n",
      "1,1,1,1,1,1,1,1,1,1,1\r\n",
      "1,1,1,1,1,1,1,1,1,1,1\r\n",
      "0,0,1,1,0,1,1,0,0,0,1\r\n",
      "0,0,0,0,0,0,0,0,0,0,0\r\n",
      "1,1,0,0,1,0,0,1,1,1,0\r\n"
     ]
    }
   ],
   "source": [
    "! python3 bertrand_predict.py bertrandtest.csv > bertrand_prediction.csv\n",
    "! head bertrand_prediction.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}